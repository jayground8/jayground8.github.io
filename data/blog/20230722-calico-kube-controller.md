---
title: 'Calico kube-controller ì´í•´í•˜ê¸°'
date: '2023-07-22'
tags: ['kubernetes', 'calico']
summary: 'Calicoì—ì„œ ì–´ë–»ê²Œ CRDë¥¼ í™œìš©í•˜ëŠ”ì§€ ì´í•´í•˜ê¸° ìœ„í•´ì„œ Calico Opensource ë²„ì „ì˜ ê¹ƒí—™ ì†ŒìŠ¤ì½”ë“œë¥¼ ì‚´í´ë³´ê²Œ ë˜ì—ˆë‹¤. Calico archiectureì—ì„œ kube-controller ë¶€ë¶„ì´ ì–´ë–¤ ì—­í• ì„ í•˜ëŠ”ì§€ ì†ŒìŠ¤ ì½”ë“œë¥¼ í†µí•´ì„œ ì´í•´í•  ìˆ˜ ìˆê²Œ ë˜ì—ˆë‹¤. kube-controllerë“¤ì€ kubernetes native resourceì— ëŒ€í•œ ë³€ê²½ì„ calico data storeì™€ syncí•´ì£¼ëŠ” ì—­í• ì„ í•˜ê³  ìˆë‹¤. ë‚´ê°€ ì‚¬ìš©í•˜ëŠ” Minikbue Kubernetes Clusterì—ì„œëŠ” Calicoì˜ data storeëŠ” kubernetesë¡œ ì„¤ì •ë˜ì–´ ìˆê¸° ë•Œë¬¸ì—, CRDë¡œ Calico dataë“¤ì´ ì €ì¥ë˜ê³  Felixê°€ ì´ê²ƒì„ watchí•˜ì—¬ ë³€í™”ì— ëŒ€í•´ì„œ network ruleì„ ì—…ë°ì´íŠ¸ í•˜ê²Œ ëœë‹¤.'
---

ì´ì „ì— `kubebuilder`ë¥¼ í†µí•´ì„œ `Programming Kubernetes`ì—ì„œ ì„¤ëª…í•œ [At resourceë¥¼ watchí•˜ëŠ” Custom controllerë¥¼ ì§ì ‘ ì‘ì„±](https://jayground8.github.io/blog/20230715-k8s-controller)í–ˆë‹¤. ê·¸ë‹¤ìŒì—ëŠ” ifkakao(2022) `Testing Kubernetes Controller` ë°œí‘œì—ì„œ ì‚¬ìš©ëœ [exampleì¸ BlueGreen resourceì— ëŒ€í•œ Custom controllerë¥¼ kubebuilderë¡œ ì‘ì„±](https://jayground8.github.io/blog/20230716-if-kakao-2022-k8s-controller)í–ˆë‹¤. ì´ë²ˆì—ëŠ” Calicoì—ì„œ ì–´ë–»ê²Œ CRDì™€ Custom contollerë¥¼ í™œìš©í•˜ê³  ìˆëŠ”ì§€ [Source code](https://github.com/projectcalico/calico)ë¥¼ í™•ì¸í•´ë´¤ë‹¤. (ì´ ê¸€ì„ ì‘ì„±í•˜ëŠ” ì‹œì ì—ëŠ” Calico OpenSource Version 3.26ì„ í™•ì¸í•˜ì˜€ë‹¤.)

## Calico kube-controllers

source codeë¥¼ ë³´ë©´ `kube-controllers` ë””ë ‰í„°ë¦¬ ì•ˆì— ì•„ë˜ì²˜ëŸ¼ controller ì½”ë“œê°€ ìˆëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.

```bash
.
â”œâ”€â”€ controller
â”‚   â””â”€â”€ controller.go
â”œâ”€â”€ flannelmigration
â”‚   â”œâ”€â”€ config.go
â”‚   â”œâ”€â”€ config_test.go
â”‚   â”œâ”€â”€ flannel_migration_fv_test.go
â”‚   â”œâ”€â”€ flannelmigration_suite_test.go
â”‚   â”œâ”€â”€ ipam_migrator.go
â”‚   â”œâ”€â”€ k8s_resources.go
â”‚   â”œâ”€â”€ migration_controller.go
â”‚   â””â”€â”€ network_migrator.go
â”œâ”€â”€ namespace
â”‚   â”œâ”€â”€ namespace_controller.go
â”‚   â”œâ”€â”€ namespace_controller_fv_test.go
â”‚   â””â”€â”€ namespace_suite_test.go
â”œâ”€â”€ networkpolicy
â”‚   â”œâ”€â”€ policy_controller.go
â”‚   â”œâ”€â”€ policy_controller_fv_test.go
â”‚   â””â”€â”€ policy_suite_test.go
â”œâ”€â”€ node
â”‚   â”œâ”€â”€ auto_hep_fv_test.go
â”‚   â”œâ”€â”€ controller.go
â”‚   â”œâ”€â”€ errors.go
â”‚   â”œâ”€â”€ etcd_ipam_gc_fv_test.go
â”‚   â”œâ”€â”€ fake_client.go
â”‚   â”œâ”€â”€ hostendpoints.go
â”‚   â”œâ”€â”€ ipam.go
â”‚   â”œâ”€â”€ ipam_allocation.go
â”‚   â”œâ”€â”€ ipam_test.go
â”‚   â”œâ”€â”€ kdd_ipam_gc_fv_test.go
â”‚   â”œâ”€â”€ labels.go
â”‚   â”œâ”€â”€ metrics_fv_test.go
â”‚   â”œâ”€â”€ node_controller_fv_test.go
â”‚   â”œâ”€â”€ node_deleter.go
â”‚   â”œâ”€â”€ node_suite_test.go
â”‚   â”œâ”€â”€ pool_manager.go
â”‚   â””â”€â”€ syncer.go
â”œâ”€â”€ pod
â”‚   â”œâ”€â”€ pod_controller.go
â”‚   â”œâ”€â”€ pod_controller_fv_test.go
â”‚   â””â”€â”€ pod_suite_test.go
â””â”€â”€ serviceaccount
    â”œâ”€â”€ serviceaccount_controller.go
    â”œâ”€â”€ serviceaccount_controller_fv_test.go
    â””â”€â”€ serviceaccount_suite_test.go
```

`Makefile`ë¥¼ í™•ì¸í•´ë³´ë©´ ì•„ë˜ì™€ ê°™ì´ buildí™˜ê²½ì„ ê°–ì¶˜ Container Imageë¥¼ í†µí•´ì„œ compileì„ í•˜ê²Œ ëœë‹¤. (ê¸°íƒ€ arguments ìƒëµ)

```bash
go build -o bin/kube-controllers-linux-amd64 ./cmd/kube-controllers/
```

buildí•˜ëŠ” `/cmd/kube-controllers`ì˜ `main.go`ë¥¼ í™•ì¸í•´ë³´ë©´, `controllerControl`ì´ë¼ëŠ” struct typeì— Controller instanceë“¤ì„ ì €ì¥í•˜ê²Œ ëœë‹¤.

```go
controllerCtrl := &controllerControl{
		ctx:         ctx,
		controllers: make(map[string]controller.Controller),
		stop:        stop,
		informers:   make([]cache.SharedIndexInformer, 0),
	}
```

`InitControllers` methodë¥¼ í™•ì¸í•˜ë©´ ì„¤ì •ê°’ì— ë”°ë¼ì„œ `Pod`, `Namespace`, `NetworkPolicy`, `Node`, `ServiceAccount`ì— ê´€ë ¨ëœ controllerë¥¼ ì„¤ì •í•˜ê²Œ ëœë‹¤.

```go
controllerCtrl.InitControllers(ctx, runCfg, k8sClientset, calicoClient)
```

```go
if cfg.Controllers.WorkloadEndpoint != nil {
  podController := pod.NewPodController(...ìƒëµ)
  cc.controllers["Pod"] = podController
  cc.registerInformers(podInformer)
}

if cfg.Controllers.Namespace != nil {
  namespaceController := namespace.NewNamespaceController(...ìƒëµ)
  cc.controllers["Namespace"] = namespaceController
}

...ìƒëµ
```

[kube-controllerì— ëŒ€í•œ ì„¤ì •ê°’ì„ ë¬¸ì„œ](https://docs.tigera.io/calico/latest/reference/kube-controllers/configuration#the-calicokube-controllers-container)ë¥¼ í™•ì¸í•´ë³´ë©´ calico datasourceë¡œ Kubernetesì˜ etcdë¥¼ ê³µìœ í•´ì„œ ì‚¬ìš©í•˜ê³  ì‹¶ìœ¼ë©´ í™˜ê²½ ë³€ìˆ˜ `DATASTORE_TYPE` ê°’ì„ `kubernetes`ë¡œ ì„¤ì •í•´ì¤˜ì•¼ í•œë‹¤. ê·¸ë¦¬ê³  `node`ì— ê´€í•œ `kube-controller`ë¥¼ enableí•˜ê¸° ìœ„í•´ì„œ `ENABLED_CONTROLLERS`í™˜ê²½ë³€ìˆ˜ë¥¼ `node`ë¡œ ì„¤ì •í•´ì•¼ í•œë‹¤. ë‚˜ë¨¸ì§€ controllerëŠ” defaultë¡œ enableë˜ê¸° ë•Œë¬¸ì— ì‚¬ìš©í•˜ì§€ ì•Šê³  ì‹¶ì„ ë•Œë§Œ ëª…ì‹œì ìœ¼ë¡œ í™˜ê²½ë³€ìˆ˜ë¡œ disable ì‹œì¼œì¤˜ì•¼ í•œë‹¤.

ë‚˜ëŠ” Minikubeì—ì„œ Addonìœ¼ë¡œ Calicoë¥¼ ì¶”ê°€í•´ì„œ Kubernetes clusterë¥¼ ì‚¬ìš©í•˜ê³  ìˆë‹¤. ê·¸ë˜ì„œ `calico-kube-controllers`ì˜ í™˜ê²½ë³€ìˆ˜ ì„¤ì •ê°’ì„ í™•ì¸í•˜ë‹ˆ ì•„ë˜ì²˜ëŸ¼ ì„¤ì •ëœ ê²ƒì„ í™•ì¸ í•  ìˆ˜ ìˆì—ˆë‹¤.

```bash
kubectl describe deployments calico-kube-controllers -n kube-system
```

```bash
Environment:
  ENABLED_CONTROLLERS:  node
  DATASTORE_TYPE:       kubernetes
```

ê·¸ë‹¤ìŒì— `main.go`ì—ì„œ ìµœì¢…ì ìœ¼ë¡œ `RunController` methodë¥¼ í˜¸ì¶œí•˜ê³ , goroutineìœ¼ë¡œ `controllerControl` structì— ì¶”ê°€í–ˆë˜ `informer`ì™€ `controller`ë“¤ì˜ Run methodë¥¼ í˜¸ì¶œí•´ì¤€ë‹¤.

```go
func (cc *controllerControl) RunControllers() {
	for _, inf := range cc.informers {
		log.WithField("informer", inf).Info("Starting informer")
		go inf.Run(cc.stop)
	}

	for controllerType, c := range cc.controllers {
		log.WithField("ControllerType", controllerType).Info("Starting controller")
		go c.Run(cc.stop)
	}

	select {
	case <-cc.ctx.Done():
		log.Warn("context cancelled")
	case <-cc.restart:
		log.Warn("configuration changed; restarting")
	}
	close(cc.stop)
}
```

`c.Run(cc.stop)`ì€ ì•„ë˜ì²˜ëŸ¼ work processë¥¼ groutineìœ¼ë¡œ ì‹¤í–‰í•˜ê²Œ ë˜ê³ , workqueueì— itemì´ ì¶”ê°€ë ë•Œê¹Œì§€ ê¸°ë‹¤ë¦¬ê²Œ ë˜ëŠ” ë¬´í•œ loopìœ¼ë¡œ ëŒì•„ê°„ë‹¤.

```go
for i := 0; i < c.cfg.NumberOfWorkers; i++ {
		go c.runWorker()
	}

...ìƒëµ

func (c *namespaceController) runWorker() {
	for c.processNextItem() {
	}
}

func (c *namespaceController) processNextItem() bool {
	workqueue := c.resourceCache.GetQueue()
  ... ìƒëµ
  workqueue.Done(key)
	return true
}
```

ê°ê°ì˜ contollerê°€ í•˜ëŠ” ì¼ì€ [ë¬¸ì„œì—ì„œ ì•„ë˜ì²˜ëŸ¼ ì¹œì ˆí•˜ê²Œ ì„¤ëª…ë˜ì–´ ìˆë‹¤](https://docs.tigera.io/calico/latest/reference/kube-controllers/configuration#the-calicokube-controllers-container).

- policy controller: watches Kubernetes network policies in the Kubernetes API, and syncs the policies to the datastore (etcd) as Calico network policies. Felix implements network policies in the dataplane.
- namespace controller: watches namespaces and programs Calico profiles.
- serviceaccount controller: watches service accounts and programs Calico profiles.
- workloadendpoint controller: watches for changes to pod labels and updates Calico workload endpoints.
- node controller: watches for the removal of Kubernetes nodes and removes corresponding data from Calico, and optionally watches for node updates to create and sync host endpoints for each node.

ì´ì œ controllerì˜ ì½”ë“œë¥¼ í™•ì¸í•´ë³¸ë‹¤. ì´ì „ì—ëŠ” kubebuilderë¡œ bootstrapì„ í•´ì„œ ì‘ì„±ì„ í–ˆì—ˆë‹¤. calicoì—ì„œëŠ” kubebuilderë¥¼ ì“°ëŠ” ê²ƒì´ ì•„ë‹ˆê¸° ë•Œë¬¸ì—, [kubernetes code-generator](https://github.com/kubernetes/code-generator)ë¥¼ í™œìš©í•˜ì—¬ custom controllerë¥¼ ì‘ì„±í•˜ëŠ” ë°©ë²•ì„ ì°¸ì¡°í•˜ì—¬ ì½”ë“œë¥¼ ì´í•´í–ˆë‹¤.

### pod controller

`workloadendpoint controller`ëŠ” Pod informerë¥¼ ì‚¬ìš©í•˜ê³  ìˆë‹¤. `informer factory`ë¥¼ í†µí•´ì„œ workerë“¤ì´ ê³µìœ í•´ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” `informer`ë¥¼ ìƒì„±í•œë‹¤.

```go
factory := informers.NewSharedInformerFactory(k8sClientset, 0)
podInformer := factory.Core().V1().Pods().Informer()
```

`controller`ì—ì„œëŠ” ì¸ìë¡œ ì „ë‹¬ëœ informerì— ì´ì œ `ADD`, `UPDATE`, `DELETE` eventë¥¼ ì²˜ë¦¬í•  event handlerë¥¼ ì¶”ê°€í•˜ê²Œ ëœë‹¤.

```go
if _, err := informer.AddEventHandler(cache.ResourceEventHandlerFuncs{
		AddFunc: func(obj interface{}) {
    },
    UpdateFunc: func(oldObj interface{}, newObj interface{}) {
    },
    DeleteFunc: func(obj interface{}) {
    }
}
```

InformerëŠ” cacheë¥¼ í†µí•´ì„œ ë§¤ë²ˆ API serverì— ìš”ì²­í•  í•„ìš”ê°€ ì—†ê³ , polling ëŒ€ì‹ ì— watchë¡œ resourceì— ëŒ€í•œ ë³€í™” Eventì— ì‘ë™ë  ìˆ˜ ìˆëŠ” Interfaceë¥¼ ì œê³µí•œë‹¤. Controllerì—ì„œëŠ” ì •ì˜ëœ Informerì— eventì— ë”°ë¼ ì‹¤í–‰í•  ë¡œì§ì„ event handlerë¥¼ ë“±ë¡í•˜ì—¬ ì¶”ê°€í•˜ê²Œ ëœë‹¤. ì´ë ‡ê²Œ `podInformer`ë¡œ Pod objectê°€ ë³€í™”ë  ë•Œë§ˆë‹¤ calico data storeì™€ syncë¥¼ ë§ì¶°ì¤€ë‹¤.

calico custom resourceì— ëŒ€í•œ Interfaceì œê³µí•˜ëŠ” clientsetsì€ ì•„ë˜ì²˜ëŸ¼ WorkloadEndpointsë¥¼ ì²˜ìŒ ê°€ì ¸ì™€ì„œ cacheì— ë‹´ëŠ”ë° ì‚¬ìš©í•œë‹¤.

```go
workloadEndpoints, err := c.WorkloadEndpoints().List(ctx, options.ListOptions{})
```

### networkpolicy controller

Pod resourceì— ëŒ€í•œ informerëŠ” `NewSharedInformerFactory`ì„ í†µí•´ì„œ ì´ì œ ì—¬ëŸ¬ workerì´ ê³µìœ í•´ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ í–ˆëŠ”ë°, networkpolicy controllerì—ì„œëŠ” ì•„ë˜ì²˜ëŸ¼ informerë¥¼ ìƒì„±í•˜ê³  ìˆë‹¤. ì´ë ‡ê²Œ í•œ ì´ìœ ëŠ” pod informerì˜ ê²½ìš°ì—ëŠ” node controllerì™€ pod controllerê°€ ë‘˜ë‹¤ ì‚¬ìš©í•˜ê³  ìˆê¸° ë•Œë¬¸ì´ê³ , networkpolicy resourceì— ëŒ€í•´ì„œëŠ” ì—¬ëŸ¬ workerê°€ ì‚¬ìš©í•˜ì§€ ì•Šìœ¼ë‹ˆê¹ ì´ë ‡ê²Œ ìƒì„±í•œ ê²ƒì¼ê¹Œ? ê·¸ë ‡ë‹¤ë©´ node informerëŠ” node controllerì—ì„œ ë°–ì— ì‚¬ìš©í•˜ì§€ ì•ŠëŠ”ë°, ì™œ `NewSharedInformerFactory`ë¥¼ ì‚¬ìš©í–ˆì„ê¹Œ?

```go
listWatcher := cache.NewListWatchFromClient(
  clientset.NetworkingV1().RESTClient(),
  "networkpolicies", "",
  fields.Everything()
)

_, informer := cache.NewIndexerInformer(listWatcher, &networkingv1.NetworkPolicy{}, 0, cache.ResourceEventHandlerFuncs{
		AddFunc: func(obj interface{}) {
    },
    UpdateFunc: func(oldObj interface{}, newObj interface{}) {
    },
    DeleteFunc: func(obj interface{}) {
    }
  }, cache.Indexers{})
```

`pod Controller`ì™€ ë™ì¼í•˜ê²Œ Kubernetes NetworkPolicy resourceê°€ `ADD`, `UPDATE`, `DELETE`ë˜ì—ˆì„ ë•Œ, calico datastoreë¥¼ ì—…ë°ì´íŠ¸ í•´ì£¼ëŠ” ì—­í• ì„ í•œë‹¤. ê·¸ë¦¬ê³  ì•„ë˜ì²˜ëŸ¼ calico clientsetsìœ¼ë¡œ `projectcalico.org` Group `v3` Version `NetworkPolicy` Kindë¥¼ ê°€ì ¸ì˜¤ê³  ìˆë‹¤.

```go
calicoPolicies, err := c.NetworkPolicies().List(ctx, options.ListOptions{})
```

### Calico CRDì™€ ì—°ê²°ì ì€ ì–´ë–»ê²Œ ë˜ëŠ”ê±°ì§€?

[code-generatorë¥¼ ì‚¬ìš©í•˜ëŠ” At custom controllerì˜ ì†ŒìŠ¤ ì½”ë“œ](https://github.com/programming-kubernetes/cnat/blob/master/cnat-client-go/main.go)ë¥¼ ë³´ë©´ ì•„ë˜ì²˜ëŸ¼ custom resourceì— ëŒ€í•´ì„œ code-generatorë¡œ ìƒì„±ëœ informerë¥¼ ì‚¬ìš©í•˜ê³  ìˆë‹¤. At resourceê°€ ë³€ê²½ë  ë•Œ, Eventì— ë”°ë¼ì„œ ë¡œì§ì„ ìˆ˜í–‰í•˜ê²Œ ëœë‹¤.

```go
informers "github.com/programming-kubernetes/cnat/cnat-client-go/pkg/generated/informers/externalversions"

...ìƒëµ
cnatInformerFactory := informers.NewSharedInformerFactory(cnatClient, time.Minute*10)
```

`Calico`ë¥¼ Addonìœ¼ë¡œ ì¶”ê°€í•œ Minikubeì—ì„œ `kubectl get crds`ë¥¼ ì‹¤í–‰í•˜ë©´ ì•„ë˜ì²˜ëŸ¼ `crd`ê°€ ìˆëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. `pod controller`, `network policy contoller`, `service account controller`ë¥¼ ë³´ë©´, kubernetestì˜ native resourceê°€ ë³€í™”í•  ë•Œ informerë¥¼ í†µí•´ì„œ calico data storeë¥¼ syncí•˜ê³  ìˆë‹¤. ê·¸ëŸ°ë° ì•„ë˜ì˜ CRDì˜ custom resourceê°€ ë³€ê²½ë˜ëŠ” ê±°ì— ëŒ€í•´ì„œ ë¡œì§ì„ ìˆ˜í–‰í•˜ëŠ” ì½”ë“œëŠ” controllerì— ì—†ë‹¤. ê·¸ëŸ¼ ê·¸ë¶€ë¶„ì€ ì–´ë””ì„œ ë‹´ë‹¹í•˜ê³  ìˆëŠ” ê²ƒì¼ê¹Œ?

```bash
NAME                                                  CREATED AT
bgpconfigurations.crd.projectcalico.org               2023-07-03T07:55:54Z
bgppeers.crd.projectcalico.org                        2023-07-03T07:55:54Z
blockaffinities.crd.projectcalico.org                 2023-07-03T07:55:54Z
caliconodestatuses.crd.projectcalico.org              2023-07-03T07:55:54Z
clusterinformations.crd.projectcalico.org             2023-07-03T07:55:54Z
felixconfigurations.crd.projectcalico.org             2023-07-03T07:55:54Z
globalnetworkpolicies.crd.projectcalico.org           2023-07-03T07:55:55Z
globalnetworksets.crd.projectcalico.org               2023-07-03T07:55:55Z
hostendpoints.crd.projectcalico.org                   2023-07-03T07:55:55Z
ipamblocks.crd.projectcalico.org                      2023-07-03T07:55:55Z
ipamconfigs.crd.projectcalico.org                     2023-07-03T07:55:55Z
ipamhandles.crd.projectcalico.org                     2023-07-03T07:55:55Z
ippools.crd.projectcalico.org                         2023-07-03T07:55:55Z
ipreservations.crd.projectcalico.org                  2023-07-03T07:55:55Z
kubecontrollersconfigurations.crd.projectcalico.org   2023-07-03T07:55:55Z
networkpolicies.crd.projectcalico.org                 2023-07-03T07:55:55Z
networksets.crd.projectcalico.org                     2023-07-03T07:55:55Z
```

calicoctlì„ í†µí•´ì„œ custom resourceë¥¼ ìƒì„±í•´ë³¸ë‹¤. (calicoctlì„ í†µí•´ì„œ calicoì—ì„œ í•„ìš”í•œ validationê³¼ defaultingì„ ìˆ˜í–‰í•œë‹¤. ê·¸ëŸ°ë° calico apiserverë¥¼ ì„¤ì¹˜í•˜ë©´ calicoctlì—†ì´ ê·¸ëƒ¥ kubectlì„ ì´ìš©í•´ì„œ í•  ìˆ˜ ìˆë‹¤.)

```bash
calicoctl create -f - <<EOF
apiVersion: projectcalico.org/v3
kind: NetworkPolicy
metadata:
  name: allow-busybox-egress
  namespace: advanced-policy-demo
spec:
  selector: run == 'access'
  types:
  - Egress
  egress:
  - action: Allow
EOF
```

`kubectl api-resources`ë¡œ í™•ì¸í•´ë³´ë©´ NetworkPolicyë¡œ ë™ì¼í•œ KINDì¸ë° Groupê³¼ Versionì´ ë‹¤ë¥¸ ê²ƒì´ ë³´ì¸ë‹¤.

```bash
NAME                              SHORTNAMES   APIVERSION                             NAMESPACED   KIND
networkpolicies                                crd.projectcalico.org/v1               true         NetworkPolicy
networkpolicies                   netpol       networking.k8s.io/v1                   true         NetworkPolicy
```

`kubectl get networkpolicy -A`ë¥¼ í•˜ê²Œ ë˜ë©´, networking.k8s.io/v1ì˜ NetworkPolicyë§Œ ë³´ì—¬ì£¼ê¸° ë•Œë¬¸ì— ì•„ë˜ì²˜ëŸ¼ Groupê³¼ Versionì„ ëª…ì‹œí•´ì„œ resourceë¥¼ ê°€ì ¸ì™”ë‹¤.

```bash
kubectl get networkpolicy.v1.crd.projectcalico.org
```

ì´ë ‡ê²Œ Custom Resourceë¥¼ ìƒì„±í–ˆìœ¼ë©´ ì´ê²ƒì´ Calicoì˜ data storeì™€ syncê°€ ë˜ê³ , ê·¸ ë°ì´í„°ë¥¼ í†µí•´ì„œ Felixê°€ iptables ruleì´ë‚˜ eBPFë¡œ í•´ë‹¹ ë‚´ìš©ì„ ì ìš©í•  ê²ƒì´ë‹¤. ê·¸ëŸ°ë° Calico systemì—ì„œ custom resourceê°€ ìƒì„±ë˜ê³ ë‚˜ ë³€ê²½ëœ ê²ƒì„ íƒì§€í•´ì„œ ê·¸ê²ƒì— ë”°ë¼ì„œ ë¡œì§ì„ ìˆ˜í–‰í•˜ëŠ” ë¶€ë¶„ì€ ì–´ë””ì—ì„œ ì°¾ì„ ìˆ˜ ìˆëŠ”ê±°ì§€? ğŸ¤”

CalicoëŠ” Kubernetesë§ê³  OpenStackì´ë‚˜ clusterê°€ ì•„ë‹Œ í™˜ê²½ì—ì„œë„ ì„¤ì¹˜í•´ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ê²ƒì„ ìƒê°í•˜ë©´ Kubernetesì™€ì˜ couplingì„ ìµœì†Œí•œìœ¼ë¡œ í–ˆì„ ê²ƒì´ë¼ ì¶”ì¸¡í–ˆë‹¤. ê·¸ë˜ì„œ Calico nodeëŠ” Kubernetesì˜ ì¡´ì¬ëŠ” ëª¨ë¥´ê³  calico datasourceì˜ ë³€í™”ì— ëŒ€í•´ì„œ eventë¥¼ ë°›ì•„ì„œ ë¡œì§ì´ ìˆ˜í–‰ëœë‹¤ê³  ìƒê°í–ˆë‹¤. Kubernetesì™€ì˜ couplingì„ ìµœì†Œí•œìœ¼ë¡œ í•˜ê³ , kubernetes native resourceê°€ ë³€í™”í•˜ëŠ” ê²ƒì— ëŒ€í•´ì„œëŠ” kube-controllerë¡œ watchí•´ì„œ ë³€í™”ëœ ë‚´ìš©ì„ calico datasourceì— syncë¥¼ í•´ì£¼ëŠ” ê²ƒì¼ ê²ƒì´ë‹¤. ê·¸ëŸ°ë° Kubernetes CRDê°€ `projectcalico.org` groupìœ¼ë¡œ ë§ì€ ê²ƒì´ ì¡´ì¬í•˜ëŠ”ë°, ì´ê²ƒì´ ì–´ë–»ê²Œ Calico systemì— ë°˜ì˜ì´ ë˜ëŠ”ì§€ ì˜ì•„í–ˆë‹¤. ì–´ì œ ë¸”ë¡œê·¸ë¥¼ ì •ë¦¬í•  ë•ŒëŠ” ì‹¤ë§ˆë¦¬ê°€ ë³´ì´ì§€ ì•Šì•˜ëŠ”ë°, ë¬¸ë“ calicoctlì´ë‚˜ calico apiserverê°€ í•˜ê³  ìˆì„ ê²ƒì´ë¼ëŠ” ìƒê°ì´ ë“¤ì—ˆë‹¤. calicoctlë¡œ ì ìš©ì„ í•˜ë©´ calico datasourceì™€ kubernetes CRDë¥¼ ê°™ì´ ë³€ê²½í•˜ëŠ” ê²ƒì´ë‹¤. kubernetes custom resourceë¥¼ controllerë¡œ watchí•˜ì—¬ statusë¥¼ ë§ì¶°ì£¼ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, ê·¸ëƒ¥ clientì—ì„œ custom resourceë¥¼ ì ìš©í•  ë•Œ ì‘ì—…ì„ í•´ì£¼ëŠ” ê²ƒì´ë‹¤. calico apiserverë¥¼ ì‚¬ìš©í•˜ì—¬ ê·¸ëƒ¥ kubectlë¥¼ ì ìš©í•œë‹¤ë©´, ì´ë¶€ë¶„ì´ ë“¤ì–´ê°€ì§€ ì•Šì•˜ì„ê¹Œ? ì´ëŸ¬í•œ ìƒê°ì„ ê°€ì§€ê³  ë‹¤ì‹œ í•œë²ˆ ì†ŒìŠ¤ ì½”ë“œë¥¼ ì‚´í´ë³´ê²Œ ë˜ì—ˆë‹¤.

calicoctlì˜ ì½”ë“œë¥¼ ë³´ë©´ ìµœì¢…ì ìœ¼ë¡œ `libcalico-go/lib/clientv3`ë¥¼ ì‚¬ìš©í•˜ê²Œ ëœë‹¤. clientv3ì—ì„œ `networkPolicies`ì˜ method `Create`ë¥¼ ì‚´í´ë³´ë©´ ì•„ë˜ì™€ ê°™ë‹¤. calico apiserverë¥¼ ì‚¬ìš©í•˜ë©´ ì´ê²Œ ëŒ€ì‹ ì— defaultingê³¼ validationì„ í•´ì£¼ëŠ”ë°, ì—¬ê¸°ì— ê·¸ì— ëŒ€í•œ ë¡œì§ì´ ë“¤ì–´ê°€ ìˆë‹¤. `libcalico-go`ëŠ” ì´ì œ calicoì—ì„œ ë‚´ë¶€ì ìœ¼ë¡œ ì‚¬ìš©í•˜ê¸° ìœ„í•œ ì½”ë“œì´ê³ , ì´ê±¸ custom controllerë¥¼ ë§Œë“¤ ë•Œ code-generatorë¡œ ë§Œë“  clientSetsëŒ€ì‹ ì— ì‚¬ìš©í•˜ëŠ” ì´ìœ ì´ë‹¤. ì´ë ‡ê²Œ defaultingê³¼ validationì„ í•˜ê³  custom resourceë¥¼ ìƒì„±í•´ì£¼ê³  ìˆë‹¤.

```go
func (r networkPolicies) Create(ctx context.Context, res *apiv3.NetworkPolicy, opts options.SetOptions) (*apiv3.NetworkPolicy, error) {
	if res != nil {
		// Since we're about to default some fields, take a (shallow) copy of the input data
		// before we do so.
		resCopy := *res
		res = &resCopy
	}
	defaultPolicyTypesField(res.Spec.Ingress, res.Spec.Egress, &res.Spec.Types)

	if err := validator.Validate(res); err != nil {
		return nil, err
	}

	// Properly prefix the name
	res.GetObjectMeta().SetName(convertPolicyNameForStorage(res.GetObjectMeta().GetName()))
	out, err := r.client.resources.Create(ctx, opts, apiv3.KindNetworkPolicy, res)
	if out != nil {
		// Remove the prefix out of the returned policy name.
		out.GetObjectMeta().SetName(convertPolicyNameFromStorage(out.GetObjectMeta().GetName()))
		return out.(*apiv3.NetworkPolicy), err
	}

	// Remove the prefix out of the returned policy name.
	res.GetObjectMeta().SetName(convertPolicyNameFromStorage(res.GetObjectMeta().GetName()))
	return nil, err
}
```

ìƒê°í•´ë³´ë‹ˆ ë‚˜ì˜ Minikube Kubernetes clusterí™˜ê²½ì—ì„œ Calico datastore Kubernetesë¥¼ ì‚¬ìš©í•˜ë„ë¡ ì„¤ì •ì´ ë˜ì–´ ìˆë‹¤. CRDë¡œ ì¡´ì¬í•˜ëŠ” ê²ƒë“¤ì´ Calico datastoreì˜ dataì¸ ê²ƒì´ê³ , ì˜ˆë¥¼ ë“¤ì–´ì„œ custom resourceì¸ GlobalNetworkPolicyë‚˜ NetworkPolicyë¥¼ ìƒì„±í•˜ë©´, ê·¸ê²ƒì´ Calico datastoreì— ì €ì¥ì´ ëœ ê²ƒì´ë‹¤. Calico datastoreë¥¼ ë³„ë„ì˜ etcdv3ë¡œ ì„¤ì •í•˜ì§€ ì•Šê³ , Kubernetesë¥¼ í–ˆê¸° ë•Œë¬¸ì— ì´ëŸ¬í•œ CRDê°€ ìƒì„±ëœ ê²ƒì´ë‹¤. ë”°ë¼ì„œ kubectl + calico apiserverë‚˜ calicoctlë¡œ CRDë¥¼ ìƒì„±í•œë‹¤ëŠ” ê²ƒì€ Calico data storeì— ë°ì´í„°ë¥¼ ì €ì¥/ë³€ê²½í•˜ëŠ” ê²ƒì´ë‹¤. ë”°ë¼ì„œ FelixëŠ” ì´ CRDì˜ custom resourceì˜ ë³€í™”ì— ë”°ë¼ì„œ network ruleì„ ì •ì˜í•  ê²ƒì´ë‹¤. ì´ì œ Felix ì†ŒìŠ¤ì½”ë“œì—ì„œ `daemon.go`ë¥¼ ë³´ë©´, `flexsyncer` instanceë¥¼ ìƒì„±í•˜ëŠ” ê²ƒì„ ë³¼ ìˆ˜ ìˆë‹¤.

`daemon.go`

```go
func Run(configFile string, gitVersion string, buildDate string, gitRevision string) {
  ...ìƒëµ
  } else {
		// Use the syncer locally.
		syncer = felixsyncer.New(backendClient, datastoreConfig.Spec, syncerToValidator, configParams.IsLeader())

		log.Info("using resource updates where applicable")
		configParams.SetUseNodeResourceUpdates(true)
	}
  ...ìƒëµ
}
```

ì´ì œ `flexsyncerv1.go`ë¥¼ ì‚´í´ë³´ë©´ ì´ë ‡ê²Œ go typeìœ¼ë¡œ ì •ì˜ëœ Kind ì¢…ë¥˜ë¥¼ ì •ì˜í•˜ëŠ” ë¶€ë¶„ì´ ìƒê¸´ë‹¤. `apiv3.KindGlobalNetworkPolicy`ëŠ” GlobalNetworkPolicy Kindë¥¼ ì˜ë¯¸í•œë‹¤.

`felixsyncerv1.go`

```go
func New(client api.Client, cfg apiconfig.CalicoAPIConfigSpec, callbacks api.SyncerCallbacks, isLeader bool) api.Syncer {
  ...ìƒëµ
  if isLeader {
		// These resources are only required if this is the active Felix instance on the node.
		additionalTypes := []watchersyncer.ResourceType{
			{
				ListInterface:   model.ResourceListOptions{Kind: apiv3.KindGlobalNetworkPolicy},
				UpdateProcessor: updateprocessors.NewGlobalNetworkPolicyUpdateProcessor(),
			},
			{
				ListInterface:   model.ResourceListOptions{Kind: apiv3.KindGlobalNetworkSet},
				UpdateProcessor: updateprocessors.NewGlobalNetworkSetUpdateProcessor(),
			},
			{
				ListInterface:   model.ResourceListOptions{Kind: apiv3.KindIPPool},
				UpdateProcessor: updateprocessors.NewIPPoolUpdateProcessor(),
			},
			{
				ListInterface:   model.ResourceListOptions{Kind: libapiv3.KindNode},
				UpdateProcessor: updateprocessors.NewFelixNodeUpdateProcessor(cfg.K8sUsePodCIDR),
			},
			{
				ListInterface:   model.ResourceListOptions{Kind: apiv3.KindProfile},
				UpdateProcessor: updateprocessors.NewProfileUpdateProcessor(),
			},
			{
				ListInterface:   model.ResourceListOptions{Kind: libapiv3.KindWorkloadEndpoint},
				UpdateProcessor: updateprocessors.NewWorkloadEndpointUpdateProcessor(),
			},
			{
				ListInterface:   model.ResourceListOptions{Kind: apiv3.KindNetworkPolicy},
				UpdateProcessor: updateprocessors.NewNetworkPolicyUpdateProcessor(),
			},
			{
				ListInterface:   model.ResourceListOptions{Kind: apiv3.KindNetworkSet},
				UpdateProcessor: updateprocessors.NewNetworkSetUpdateProcessor(),
			},
			{
				ListInterface:   model.ResourceListOptions{Kind: apiv3.KindHostEndpoint},
				UpdateProcessor: updateprocessors.NewHostEndpointUpdateProcessor(),
			},
			{
				ListInterface: model.ResourceListOptions{Kind: apiv3.KindBGPConfiguration},
			},
		}
  ...ìƒëµ

  return watchersyncer.New(
		client,
		resourceTypes,
		callbacks,
	)
}
```

ìœ„ì—ì„œ 'GlobalNetworkPolicy', 'GlobalNetworkSet'ë“± í•„ìš”í•œ resourceë“¤ì— ëŒ€í•´ì„œ ì •ì˜ê°€ ë˜ì—ˆëŠ”ë°, ì´ì œ `watchersyncer.go`ì—ì„œëŠ” ê·¸ëŸ¬í•œ resourceë“¤ì„ sliceì— ì €ì¥í•œë‹¤.

`watchersyncer.go`

```go
func New(client api.Client, resourceTypes []ResourceType, callbacks api.SyncerCallbacks) api.Syncer {
	rs := &watcherSyncer{
		watcherCaches: make([]*watcherCache, len(resourceTypes)),
		results:       make(chan interface{}, 2000),
		callbacks:     callbacks,
	}
	for i, r := range resourceTypes {
		rs.watcherCaches[i] = newWatcherCache(client, r, rs.results)
	}
	return rs
}
```

ì´ì œ `run`ì´ í˜¸ì¶œë˜ë©´ ì•„ê¹Œ sliceì— ì €ì¥í•´ë†¨ë˜ resourceë³„ watcherCacheì˜ runì„ forloopì„ í†µí•´ì„œ ë‹¤ì‹œ í˜¸ì¶œí•˜ê²Œ ëœë‹¤.

`watchersyncer.go`

```go
func (ws *watcherSyncer) run(ctx context.Context) {
	log.Debug("Sending initial status event and starting watchers")
	ws.sendStatusUpdate(api.WaitForDatastore)
	for _, wc := range ws.watcherCaches {
		// no need for ws.wgwc.Add(1), been set already
		go func(wc *watcherCache) {
			defer ws.wgwc.Done()
			wc.run(ctx)
			log.Debug("Watcher cache run completed")
		}(wc)
	}
  ...ìƒëµ
}
```

ë§ˆì§€ë§‰ìœ¼ë¡œ `watchercache.go`ë¥¼ ì‚´í´ë³´ë©´ `resyncAndCreateWatcher`ê°€ í˜¸ì¶œë˜ê³ , ì´ê²ƒì€ ë¨¼ì € resyncê°€ í•„ìš”í•˜ë©´ Listë¥¼ í•˜ê³ , ê·¸ ë‹¤ìŒì— ì•ìœ¼ë¡œ ë³€í™”ëŠ” ê²ƒë§Œ Watchë¡œ Eventë¥¼ ë°›ë„ë¡ ë˜ì–´ ìˆë‹¤. ì´ì œ felixê°€ Kubernetesì˜ custom resourceë¥¼ Watchí•˜ë©´ì„œ ë³€ê²½ë˜ì—ˆì„ ë•Œ Eventë¥¼ ë°›ê³ , Eventë³„ë¡œ ì •ì˜ëœ event handler ë¡œì§ì„ ìˆ˜í–‰í•˜ê²Œ ë˜ëŠ” ê²ƒì´ë‹¤.

`watchercache.go`

```go
func (wc *watcherCache) run(ctx context.Context) {
	wc.logger.Debug("Watcher cache starting, start initial sync processing")
	wc.resyncAndCreateWatcher(ctx)
  ...ìƒëµ
}
```

`watchercache.go`

```go
func (wc *watcherCache) resyncAndCreateWatcher(ctx context.Context) {
  ...ìƒëµ
  l, err := wc.client.List(ctx, wc.resourceType.ListInterface, wc.currentWatchRevision)

  ...ìƒëµ
  w, err := wc.client.Watch(ctx, wc.resourceType.ListInterface, wc.currentWatchRevision)
}
```
