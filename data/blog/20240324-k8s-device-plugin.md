---
title: 'k8s-device-pluginìœ¼ë¡œ NVIDIA GPU Multi-Process Service ì‚¬ìš©í•˜ê¸°'
date: '2024-03-24'
tags: ['kubernetes', 'ncloud']
images: ['/static/images/social-banner.png']
summary: 'Kubernetesì—ì„œ k8s-device-pluginì„ í†µí•´ì„œ NVIDIA GPU ìì›ì„ ì‰½ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤. í•˜ë‚˜ì˜ ì–´í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ GPU ìì›ì„ ì˜¨ì „íˆ ì‚¬ìš©í•˜ì§€ ëª»í•˜ê³  ë‚­ë¹„ë  ë•Œ, Time slicing, MPS, MIG ë“±ì„ ì‚¬ìš©í•˜ì—¬ ì—¬ëŸ¬ í”„ë¡œì„¸ìŠ¤ê°€ GPU ìì›ì„ ê³µìœ í•˜ë„ë¡ ì„¤ì •í•  ìˆ˜ ìˆë‹¤. ë„¤ì´ë²„ ê³µê³µ í´ë¼ìš°ë“œì—ì„œ Tesla T4ì™€ Telsa V100ì„ ì œê³µí•œë‹¤. í•´ë‹¹ GPU ì•„í‚¤í…ì³ê°€ MIGì„ ì§€ì›íˆì§€ ì•Šê¸° ë•Œë¬¸ì—, MPSë¥¼ ì ìš©í•˜ì—¬ GPU ìì›ì„ ê³µìœ í•˜ëŠ” ê²ƒì„ ê³ ë ¤í•˜ì˜€ë‹¤. ìµœê·¼ì— releaseëœ k8s-device-plugin v0.15.0-rc.1ë¶€í„° MPSê°€ ì§€ì›ë˜ê¸° ì‹œì‘ë˜ì–´ í•´ë‹¹ ë²„ì „ìœ¼ë¡œ MPSë¥¼ ì„¤ì •í•´ë³´ì•˜ë‹¤.'
---

## ë„¤ì´ë²„ ê³µê³µ í´ë¼ìš°ë“œì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ì˜µì…˜

NVIDIA GPUëŠ” ìì›ì„ ê³µìœ í•˜ê¸° ìœ„í•œ ë°©ë²•ìœ¼ë¡œ ì•„ë˜ì™€ ê°™ì€ ë°©ë²•ë“¤ì„ ì œê³µí•œë‹¤.

- Time slicing
- Multi-Process Service
- Multi-instance GPU

ë„¤ì´ë²„ ê³µê³µ í´ë¼ìš°ë“œì—ì„œ ì‚¬ìš©í•œ ê°€ëŠ¥í•œ GPUì—ëŠ” Tesla V100(arch: Volta)ê³¼ Tesla T4(arch: Turing)ê°€ ìˆë‹¤. Hardwareë‹¨ì—ì„œ Partitionì„ í•˜ì—¬ ê²©ë¦¬í•  ìˆ˜ ìˆëŠ” `MIG(Multi-instance GPU)`ëŠ” `A100`ê³¼ ê°™ì€ `Ampere` ì•„í‚¤í…ì³ì—ì„œ ê°€ëŠ¥í•˜ë‹¤. ë”°ë¼ì„œ T4ì™€ V100ì—ì„œëŠ” `MIG`ë¥¼ ì‚¬ìš©í•  ìˆ˜ê°€ ì—†ë‹¤. ëŒ€ì‹ ì— `MPS(Multi-Process Service)`ëŠ” T4ì™€ V100 ëª¨ë‘ì—ì„œ ì‚¬ìš©ì´ ê°€ëŠ¥í•˜ë‹¤. `Time slicing` ë°©ì‹ì€ GPUë¥¼ ë§ì´ ì‚¬ìš©í•˜ëŠ” ë‹¤ìˆ˜ì˜ í”„ë¡œì„¸ìŠ¤ê°€ ê³µìœ í•´ì„œ ì‚¬ìš©í•  ë•Œ, Context Switchì— ì˜í•œ overloadê°€ ìƒë‹¹íˆ ë°œìƒí•  ìˆ˜ ìˆë‹¤. ë°˜ë©´ì— `MPS`ëŠ” í•˜ë‚˜ì˜ Cuda Contextë¥¼ ê³µìœ í•˜ê¸° ë•Œë¬¸ì—, `Time slicing`ë³´ë‹¤ Context switchì— ëŒ€í•œ overloadë¥¼ ì¤„ì¼ ìˆ˜ ìˆë‹¤. í•˜ì§€ë§Œ ì´ë ‡ê²Œ í•˜ë‚˜ì˜ Cuda Contextë¥¼ ê³µìœ í•˜ê¸° ë•Œë¬¸ì— errorê°€ ë°œìƒí–ˆì„ ë•Œ ëª¨ë“  MPS clientì— ì˜í–¥ì„ ë¯¸ì¹  ìˆ˜ ìˆë‹¤. ([Volta MPSì—ì„œëŠ” ì¢€ ì œí•œì ì¸ ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ê²ƒ ê°™ë‹¤.](https://docs.nvidia.com/deploy/mps/index.html#topic_3_3_3_2))

## k8s-device-plugin

Kubernetesì—ì„œ GPUë¥¼ kubeletì´ ì¸ì§€í•˜ê³  ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡, [NVIDIAì—ì„œ ê³µì‹ì ìœ¼ë¡œ device plugin](https://www.youtube.com/watch?v=Q2GuTUO170w&t=922s)ì„ ì œê³µí•˜ê³  ìˆë‹¤. ê·¸ë¦¬ê³  Helm chartë¥¼ ê°™ì´ ì œê³µí•œë‹¤. ë”°ë¼ì„œ Helmìœ¼ë¡œ `k8s-device-plugin`ì„ ì„¤ì¹˜ë¥¼ í–ˆë‹¤.

```bash
helm repo add nvdp https://nvidia.github.io/k8s-device-plugin
```

ì›í•˜ëŠ” Worker nodeì— Daemonsetì´ ì‹¤í–‰ë  ìˆ˜ ìˆë„ë¡ `affinity`ì™€ `tolerations` ì„¤ì •ì„ ì¶”ê°€í•˜ì˜€ë‹¤.

`values.yml`

```yaml
affinity:
  nodeAffinity:
    requiredDuringSchedulingIgnoredDuringExecution:
      nodeSelectorTerms:
        - matchExpressions:
            - key: serverType
              operator: In
              values:
                - gpu
tolerations:
  - key: nvidia.com/gpu
    operator: Exists
    effect: NoSchedule
```

ê·¸ë¦¬ê³  device plugin ì„¤ì •íŒŒì¼ì— MPS ì„¤ì •ì„ ì¶”ê°€í•˜ì˜€ë‹¤.

`config.yaml`

```yaml
version: v1
sharing:
  mps:
    resources:
      - name: nvidia.com/gpu
        replicas: 10
```

NVIDIAì˜ k8s-device-pluginì—ì„œ `v0.15.0`ë¶€í„° MPSë¥¼ ì§€ì›í•˜ê¸° ì‹œì‘í–ˆë‹¤. ì§€ê¸ˆ ì´ ê¸€ì„ ì“°ëŠ” ì‹œì ì— `v0.15.0-rc.2`ê°€ ìµœì‹  ë²„ì „ì´ê³ , ì•„ì§ `rc` í™˜ê²½ìœ¼ë¡œ ì œê³µë˜ê³  ìˆë‹¤. ë”°ë¼ì„œ Helmìœ¼ë¡œ ì„¤ì¹˜ë¥¼ í•  ë•Œ ì•„ë˜ì™€ ê°™ì´ version flagë¥¼ í†µí•´ì„œ 0.15.0-rc.2ë¥¼ ì„¤ì •í•´ì¤€ë‹¤.

```bash
helm install k8s-device-plugin nvdp/nvidia-device-plugin \
--version 0.15.0-rc.2 \
--namespace nvidia-device-plugin \
--create-namespace \
--values values.yaml \
--set-file config.map.config=config.yaml
```

Helmìœ¼ë¡œ ì„¤ì¹˜í•˜ê³  ë‚˜ë©´ ì•„ë˜ì™€ ê°™ì´ ë‘ê°œì˜ Daemonset Objectê°€ ë§Œë“¤ì–´ì§„ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. Deamonset k8s-device-plugin-nvidia-device-plugin-mps-control-daemonê°€ ì‹¤í–‰ë˜ê¸° ìœ„í•´ì„œëŠ” Worker Nodeì— nvidia.com/mps.capable=trueê°€ ì„¤ì •ë˜ì–´ì•¼ í•œë‹¤.

```bash
$ kubectl get ds -n nvidia-device-plugin
NAMESPACE              NAME                                                        DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR
nvidia-device-plugin   k8s-device-plugin-nvidia-device-plugin                      1         1         1       1            1           <none>                        5s
nvidia-device-plugin   k8s-device-plugin-nvidia-device-plugin-mps-control-daemon   0         0         0       0            0           nvidia.com/mps.capable=true   5s
```

í•´ë‹¹ Labelë•Œë¬¸ì— MPS daemonì´ ì‹¤í–‰ë˜ì§€ ëª»í–ˆê³ , ê·¸ë˜ì„œ k8s-device-plugin-nvidia-device-plugin Podì— ì•„ë˜ì™€ ê°™ì€ ì—ëŸ¬ ë¡œê·¸ê°€ ë‚¨ê²Œ ë˜ì—ˆë‹¤.

```bash
Failed to start plugin: error waiting for MPS daemon: error checking MPS daemon health: failed to send command to MPS daemon: exit status 1
```

ì´ì œ GPU worker nodeì— labelì„ ì¶”ê°€í•´ì£¼ë©´ MPS daemonì´ ì‹¤í–‰ë˜ê³ , ì •ìƒì ìœ¼ë¡œ MPSê°€ ì ìš©ëœë‹¤.

```bash
kubectl label node gpu-node nvidia.com/mps.capable=true
```

MPSì—ì„œ replicaë¥¼ 10ìœ¼ë¡œ ì„¤ì •í–ˆê¸° ë•Œë¬¸ì—, Nodeì˜ nvida.com/gpu ìì›ì„ í™•ì¸í•˜ë©´ 1ì—ì„œ 10ìœ¼ë¡œ ì¦ê°€í•œ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.

```bash
$ kubectl describe node gpu-node
Allocatable:
  cpu:                3920m
  ephemeral-storage:  47267522073
  hugepages-1Gi:      0
  hugepages-2Mi:      0
  memory:             17413608Ki
  nvidia.com/gpu:     10
  pods:               110
```

í•´ë‹¹ ë…¸ë“œì— `nvida.com/gpu` resource requestê°€ 1ì¸ Pod í•˜ë‚˜ë§Œ ìŠ¤ì¼€ì¥´ë§ì´ ë  ìˆ˜ ìˆì—ˆëŠ”ë°, ì´ì œ 10ìœ¼ë¡œ ëŠ˜ì–´ë‚˜ì„œ ë‹¤ìˆ˜ì˜ Podë¥¼ í•´ë‹¹ ë…¸ë“œì—ì„œ ì‹¤í–‰í•  ìˆ˜ ìˆê²Œ ë˜ì—ˆë‹¤.

## ê¶ê¸ˆì¦

MPSë¥¼ í†µí•´ì„œ GPU core 1ì„ 10ê°œë¡œ ë‚˜ëˆ„ë©´, ì˜ˆë¥¼ ë“¤ì–´ì„œ í•˜ë‚˜ì˜ ContainerëŠ” 8ê°œë¡œ ìš”ì²­í•˜ì—¬ GPU ìì›ì„ 80%ë¥¼ ì‚¬ìš©í•˜ê³ , ë‹¤ë¥¸ í•˜ë‚˜ëŠ” 2ê°œë¡œ ìš”ì²­í•˜ì—¬ 20%ë¥¼ ì‚¬ìš©í•˜ë„ë¡ í•˜ê³  ì‹¶ì—ˆë‹¤. í•˜ì§€ë§Œ [v0.15.0-rc.2 release note](https://github.com/NVIDIA/k8s-device-plugin/releases/tag/v0.15.0-rc.2)ë¥¼ ë³´ë©´ `failRequestsGreaterThanOne`ê°€ `true`ë¡œ ì„¤ì •ë˜ì–´ ìˆëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. ê·¸ë˜ì„œ 1ë¥¼ ì´ˆê³¼í•˜ì—¬ ìš”ì²­í•  ìˆ˜ê°€ ì—†ë‹¤.

ì´ì œ MPSë¡œ 10ê°œë¡œ ë‚˜ëˆ´ì„ ë•Œ GPUì™€ Memory ìì›ì„ 1/10ë§Œí¼ ì‚¬ìš©í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì—, containerê°€ 1/10ë³´ë‹¤ ë” ì‚¬ìš©í•˜ë„ë¡ ì„¤ì •í•  ìˆ˜ê°€ ì—†ë‹¤.

> Furthermore, each of these resources -- either nvidia.com/gpu or nvidia.com/gpu.shared -- would have access to the same fraction (1/10) of the total memory and compute resources of the GPU.

[ì´ ê¸€ì„ ì‘ì„±í•˜ëŠ” ì‹œì ìœ¼ë¡œ 3ì¼ì „ì— v0.15.0ì´ release ë˜ì—ˆëŠ”ë°,](https://github.com/NVIDIA/k8s-device-plugin/releases/tag/v0.15.0) ì•„ë˜ì™€ ê°™ì€ ë‚´ìš©ì´ ì„¤ëª…ë˜ì–´ ìˆë‹¤.

> It is not possible to "combine" MPS GPU requests to allow for access to more memory by a single container.

ë”°ë¼ì„œ GPU ìì›ì„ ê³„ì† ì‚¬ìš©í•˜ì§€ ì•Šì•„ì„œ ë‘ ê°œì˜ Containerê°€ GPU ìì›ì„ ê³µìœ í•˜ê³ , ê°€ëŠ¥í•˜ë©´ Fullë¡œ GPU ìì›ì„ ì‚¬ìš©í•˜ê³  ì‹¶ë‹¤ë©´, MPS ë°©ë²•ì€ ì í•©í•˜ì§€ ì•Šë‹¤. ì´ëŸ´ë•ŒëŠ” Context switchê°€ ë¬¸ì œê°€ ë˜ì§€ ì•ŠëŠ” ë²”ìœ„ì—ì„œ time slicingìœ¼ë¡œ ìì›ì„ ê³µìœ í•´ì•¼ í•˜ëŠ” ê²ƒì¸ê°€?ğŸ¤”
