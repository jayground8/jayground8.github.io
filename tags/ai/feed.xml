
  <rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
      <title>Jayground8</title>
      <link>https://jayground8.github.io/blog</link>
      <description>like playing in the playground</description>
      <language>kr</language>
      <managingEditor>jayground8@gmail.com (Jay)</managingEditor>
      <webMaster>jayground8@gmail.com (Jay)</webMaster>
      <lastBuildDate>Sat, 06 Jan 2024 00:00:00 GMT</lastBuildDate>
      <atom:link href="https://jayground8.github.io/tags/ai/feed.xml" rel="self" type="application/rss+xml"/>
      
  <item>
    <guid>https://jayground8.github.io/blog/20240106-gptcache</guid>
    <title>GPTCache</title>
    <link>https://jayground8.github.io/blog/20240106-gptcache</link>
    <description>GPTCache를 사용하여 LLM에 질의를 할 때, 의미적으로 유사한 질문에 대해서는 Cache에 저장된 답변 값을 사용할 수 있도록 구성해보았다. Langchain과 Langserve를 통해서 간단히 Cache를 제공하는 API server를 만들 수 있었다. Default로 설정된 GPTCache에서 의미적으로 충분히 다른 질의에 대해서도 기존 Cache값을 사용하는 False Positive 결과를 받았다. 그래서 Default로 사용된 Similarity Evaluation 방법이 어떻게 동작되는지 살펴보았다. 이해를 바탕으로 Threshold값을 변경하여 발생했던 False Positive case를 제거해보았다. 앞으로 Cache hit rate, Accuracy, Speed를 고려하여 서비스에 적합한 Evaluation 방법을 선택하기 위해서는 Default 말고 다른 옵션들도 확인할 필요가 있겠다.</description>
    <pubDate>Sat, 06 Jan 2024 00:00:00 GMT</pubDate>
    <author>jayground8@gmail.com (Jay)</author>
    <category>GPTCache</category><category>ai</category>
  </item>

    </channel>
  </rss>
