<!DOCTYPE html><html lang="en" class="scroll-smooth"><head><meta charSet="utf-8"/><script>!function(){try {var d=document.documentElement.classList;d.remove('light','dark');var e=localStorage.getItem('theme');if("system"===e||(!e&&true)){var t="(prefers-color-scheme: dark)",m=window.matchMedia(t);m.media!==t||m.matches?d.add('dark'):d.add('light')}else if(e) d.add(e)}catch(e){}}()</script><meta content="width=device-width, initial-scale=1" name="viewport"/><link rel="manifest" href="/jayground8/static/favicons/manifest.json"/><link rel="manifest" href="/jayground8/static/favicons/site.webmanifest"/><link rel="shortcut icon" href="/jayground8/static/favicons/favicon.ico"/><script async="" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-8773084925406986" crossorigin="anonymous"></script><title>Blog - Jay</title><meta name="robots" content="follow, index"/><meta name="description" content="like playing in the playground"/><meta property="og:url" content="https://jayground8.github.io/blog"/><meta property="og:type" content="website"/><meta property="og:site_name" content="Jayground8"/><meta property="og:description" content="like playing in the playground"/><meta property="og:title" content="Blog - Jay"/><meta property="og:image" content="https://jayground8.github.iosocial-banner.png"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:site"/><meta name="twitter:title" content="Blog - Jay"/><meta name="twitter:description" content="like playing in the playground"/><meta name="twitter:image" content="https://jayground8.github.iosocial-banner.png"/><link rel="canonical" href="https://jayground8.github.io/blog"/><meta name="next-head-count" content="22"/><link rel="apple-touch-icon" sizes="76x76" href="/static/favicons/apple-touch-icon.png"/><link rel="icon" type="image/png" sizes="32x32" href="/static/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="16x16" href="/static/favicons/favicon-16x16.png"/><link rel="manifest" href="/static/favicons/site.webmanifest"/><link rel="mask-icon" href="/static/favicons/safari-pinned-tab.svg" color="#5bbad5"/><meta name="msapplication-TileColor" content="#000000"/><meta name="theme-color" media="(prefers-color-scheme: light)" content="#fff"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#000"/><link rel="alternate" type="application/rss+xml" href="/feed.xml"/><link rel="preload" href="/_next/static/css/414f98a58444a4f1.css" as="style"/><link rel="stylesheet" href="/_next/static/css/414f98a58444a4f1.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-5cd94c89d3acac5f.js"></script><script src="/_next/static/chunks/webpack-690364db8bfb1f01.js" defer=""></script><script src="/_next/static/chunks/main-eea1c213342d95c3.js" defer=""></script><script src="/_next/static/chunks/pages/_app-516d385f7adbf36d.js" defer=""></script><script src="/_next/static/chunks/pages/blog-eafeb20b4191174d.js" defer=""></script><script src="/_next/static/PWwclqFnWkHCY0t6gTyza/_buildManifest.js" defer=""></script><script src="/_next/static/PWwclqFnWkHCY0t6gTyza/_ssgManifest.js" defer=""></script><script src="/_next/static/PWwclqFnWkHCY0t6gTyza/_middlewareManifest.js" defer=""></script></head><body class="bg-white text-black antialiased dark:bg-gray-900 dark:text-white"><div id="__next" data-reactroot=""><div class="mx-auto max-w-3xl px-4 sm:px-6 xl:max-w-5xl xl:px-0"><div class="flex h-screen flex-col justify-between"><header class="flex items-center justify-between py-10"><div><a aria-label="Jayground8" href="/"><div class="flex items-center justify-between"><div class="mr-3"><svg xmlns="http://www.w3.org/2000/svg" width="53.87" height="43.61" viewBox="0 0 512 512" class="fill-black dark:fill-white"><path d="M368.4 17c-8.8 1.3-18.3 5-25.3 9.9-3.8 2.5-22.6 16.1-41.9 30.1-37.1 26.9-38.6 28.3-36.3 33.9 1.7 4 4.9 5.1 14.6 5.1h8.5v128h-17.9c-18.2 0-22.2.6-27.3 4.2l-2.8 1.9V116.9l2.5-2.4c1.5-1.6 3.6-2.5 5.5-2.5s4 .9 5.5 2.5l2.5 2.4v42c0 29.1.3 42.8 1.1 44.5 2.6 5.7 11.5 5.5 13.9-.3.7-1.9 1-15.6.8-46.2-.3-40.1-.4-43.7-2.2-46.9-4.8-9-11.9-13.4-21.6-13.4-13.8 0-22.8 9.1-23.8 24.1l-.5 7.3h-31.5l-1.2-2.9c-1.6-3.9-6-5.8-9.9-4.1-1.6.6-3.5 2.5-4.1 4.1l-1.2 2.9h-63.6l-1.2-2.9c-2.5-6.2-11.5-6.2-14 0l-1.2 2.9H64.3l-.5-7.3c-1-15-10-24.1-23.8-24.1-9.7 0-16.8 4.4-21.6 13.4-1.8 3.3-1.9 7.5-2.2 75-.2 50 .1 72.3.8 74.1 2.1 5.1 8.6 6.3 12.5 2.4l2.5-2.4V116.9l2.5-2.4c3.2-3.3 7.8-3.3 11 0l2.5 2.4V448H32V284.9l-2.5-2.4c-3.8-3.9-10.2-2.7-12.4 2.2-1.6 3.4-1.6 171.2 0 174.6.6 1.4 2.2 3 3.6 3.6 1.6.7 15.6 1.1 43.7 1.1 38 0 41.5-.1 43.4-1.8 1.2-.9 33.4-50.5 71.7-110.2 38.3-59.7 70.5-109.3 71.7-110.3 1.8-1.5 4.3-1.7 19.4-1.7H288v16h-12.5c-13.1 0-16.6.8-18.3 4.4-2 4.5-138.5 216.2-140.4 217.9-1.9 1.6-5.6 1.7-47.9 1.7-31.9 0-46.6.3-48.3 1.1-5.7 2.6-5.5 11.5.3 13.9 1.9.7 16.7 1 50.1.8 46.4-.3 47.6-.3 51.5-2.5 2.2-1.1 5.1-3.3 6.5-4.7 1.3-1.5 10.1-14.7 19.6-29.4l17.1-26.7 18.4-.5c10.1-.3 19.1-.9 20-1.3.9-.5 2.1-1.9 2.8-3.3 1.5-3.4 1.5-35.4 0-38.8-1.1-2.3-4-4-8-4.8-1.3-.2 1.5-5.2 11.5-20.7l13.1-20.5.5 56.5c.3 31 .9 57.1 1.3 58 1.5 3 5.6 3.9 18.2 3.9H256v14c0 14.9.7 18.1 4.7 19.9 1.7.8 34.7 1.1 115.3 1.1s113.6-.3 115.3-1.1c1.4-.6 3-2.2 3.6-3.6 1.5-3.4 1.5-83.2 0-86.6-2.2-4.9-8.6-6.1-12.4-2.2l-2.5 2.4V480H272V272h208v107.1l2.5 2.4c3.8 3.9 10.2 2.7 12.4-2.2 1.5-3.4 1.5-115.2 0-118.6-1.8-3.9-5-4.7-18.4-4.7H464v-40.5c0-27.9-.3-41.2-1.1-42.9-2.6-5.5-11.2-5.5-13.8 0-.8 1.7-1.1 15-1.1 42.9V256h-24v-34.5c0-21.3-.4-36.4-1.1-39.7-3.6-17.3-19.3-32.9-36.7-36.7-16.2-3.4-31.4 1.1-43.3 12.9-7.4 7.3-11.2 13.9-13.4 23.2-1.8 7.9-2.1 50.3-.4 54.2 1.6 3.5 6.1 5.2 9.8 3.7 4.7-2 5.1-4.2 5.1-29.6 0-21.5.2-23.9 2.2-29.2C350.6 168.4 363 160 376 160s25.4 8.4 29.8 20.3c2.1 5.5 2.2 7.4 2.2 40.7v35H304V96h144v24.5c0 16 .4 25.3 1.1 26.9 2.6 5.5 11.2 5.5 13.8 0 .7-1.6 1.1-10.9 1.1-26.9V96h8.5c9.7 0 12.9-1.1 14.6-5.1 2.1-5.2.1-7.5-17.7-20.4C446.2 53.8 445 53 442.1 53c-4.1.1-7.5 3.5-7.5 7.7 0 4 2.2 6.3 14.8 15.3l4.8 3.5-39.1.3c-21.5.1-56.7.1-78.2 0l-39.1-.3 14.9-10.7c8.2-5.9 20.7-15.1 27.8-20.4 14.5-10.8 20.5-14 29.4-15.5 11.6-2.1 22.4 1.3 36.5 11.4 4.3 3.1 9 5.7 10.3 5.7 3.9 0 7.5-4.4 7.1-8.7-.3-3.3-1.1-4.4-7.8-9.6-15.3-11.8-32.3-17.1-47.6-14.7zM96 152v8H64v-16h32v8zm80 0v8h-64v-16h64v8zm48 0v8h-32v-16h32v8zM96 280v104h-4.5c-5.5 0-9 1.5-10.4 4.7-1.5 3.3-1.5 35.4 0 38.7 1.7 3.6 3.1 4 16.2 4.6l11.9.5-5.1 7.7L99 448H64V176h32v104zm80-27.8v76.3l-17.8 27.7-17.7 27.7-14.2.1H112V176h64v76.2zm48-37.3v38.9l-15.6 24.4c-8.6 13.3-15.8 24.5-16 24.7-.2.2-.4-28.2-.4-63.2V176h32v38.9zM256 369v76h-16V317.1l7.8-12c4.2-6.7 7.8-12.1 8-12.1.1 0 .2 34.2.2 76zm-129.1 34.7c-1.2 2.1-3.6 5.7-5.1 8l-2.9 4.3H96v-16h33.2l-2.3 3.7zM192 408v8h-15.1l3.7-5.8c2-3.1 4.4-6.7 5.2-8 .8-1.2 2.4-2.2 3.8-2.2 2.3 0 2.4.2 2.4 8z"></path><path d="M322.5 114.5c-1.6 1.5-2.5 3.6-2.5 5.5s.9 4 2.5 5.5c1.5 1.6 3.6 2.5 5.5 2.5s4-.9 5.5-2.5c1.6-1.5 2.5-3.6 2.5-5.5s-.9-4-2.5-5.5c-1.5-1.6-3.6-2.5-5.5-2.5s-4 .9-5.5 2.5zM418.5 114.5c-1.6 1.5-2.5 3.6-2.5 5.5s.9 4 2.5 5.5c1.5 1.6 3.6 2.5 5.5 2.5s4-.9 5.5-2.5c1.6-1.5 2.5-3.6 2.5-5.5s-.9-4-2.5-5.5c-1.5-1.6-3.6-2.5-5.5-2.5s-4 .9-5.5 2.5zM290.2 290.3c-5 5.3-1.3 13.7 5.9 13.7 4.7 0 7.9-3.4 7.9-8.1 0-7.1-9-10.7-13.8-5.6zM450.5 290.5c-5 4.9-1.5 13.5 5.5 13.5 4.1 0 8-3.9 8-8s-3.9-8-8-8c-1.9 0-4 .9-5.5 2.5zM358.1 322c-8.3 2.2-16.5 5.7-19.8 8.6-3.3 2.8-3.9 7.3-1.4 10.6 3.3 4.1 6.4 4.3 13.8.8 23.3-10.9 47.3-7 64.8 10.5 11.5 11.4 16.5 23.6 16.5 39.7 0 15.9-5.1 28.1-16.4 39.4C404.2 443 392.1 448 376 448s-28.1-5-39.5-16.5c-11-11.1-16.5-24.2-16.5-39.5.1-9.5 1.2-14.5 5.6-24.3 3.8-8.3 3.8-10.4.1-14.5-4.7-5.1-10.8-1.7-15.4 8.6-8.6 19.5-8.4 42.7.6 61.7 9.1 19.3 28.3 34.5 49.5 39 11.9 2.6 28.4 1.7 39.3-2.2 23.9-8.6 41.3-27.9 46.9-51.9 1.9-8.5 1.9-24.4-.1-33.1-5.9-25.5-26.7-46.6-52.5-53.3-10.1-2.6-25.8-2.6-35.9 0zM290.2 450.3c-5 5.3-1.3 13.7 5.9 13.7 4.7 0 7.9-3.4 7.9-8.1 0-7.1-9-10.7-13.8-5.6zM450.2 450.3c-5 5.3-1.3 13.7 5.9 13.7 4.7 0 7.9-3.4 7.9-8.1 0-7.1-9-10.7-13.8-5.6z"></path></svg></div><div class="hidden h-6 text-2xl font-semibold sm:block">Jayground8</div></div></a></div><div class="flex items-center text-base leading-5"><div class="hidden sm:block"><a class="p-1 font-medium text-gray-900 dark:text-gray-100 sm:p-4" href="/blog">블로그</a><a class="p-1 font-medium text-gray-900 dark:text-gray-100 sm:p-4" href="/tags">Tags</a></div><button aria-label="Toggle Dark Mode" type="button" class="ml-1 mr-1 h-8 w-8 rounded p-1 sm:ml-4"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" fill="currentColor" class="text-gray-900 dark:text-gray-100"><path d="M17.293 13.293A8 8 0 016.707 2.707a8.001 8.001 0 1010.586 10.586z"></path></svg></button><div class="sm:hidden"><button type="button" class="ml-1 mr-1 h-8 w-8 rounded py-1" aria-label="Toggle Menu"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" fill="currentColor" class="text-gray-900 dark:text-gray-100"><path fill-rule="evenodd" d="M3 5a1 1 0 011-1h12a1 1 0 110 2H4a1 1 0 01-1-1zM3 10a1 1 0 011-1h12a1 1 0 110 2H4a1 1 0 01-1-1zM3 15a1 1 0 011-1h12a1 1 0 110 2H4a1 1 0 01-1-1z" clip-rule="evenodd"></path></svg></button><div class="fixed top-0 left-0 z-10 h-full w-full transform bg-gray-200 opacity-95 duration-300 ease-in-out dark:bg-gray-800 translate-x-full"><div class="flex justify-end"><button type="button" class="mr-5 mt-11 h-8 w-8 rounded" aria-label="Toggle Menu"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" fill="currentColor" class="text-gray-900 dark:text-gray-100"><path fill-rule="evenodd" d="M4.293 4.293a1 1 0 011.414 0L10 8.586l4.293-4.293a1 1 0 111.414 1.414L11.414 10l4.293 4.293a1 1 0 01-1.414 1.414L10 11.414l-4.293 4.293a1 1 0 01-1.414-1.414L8.586 10 4.293 5.707a1 1 0 010-1.414z" clip-rule="evenodd"></path></svg></button></div><nav class="fixed mt-8 h-full"><div class="px-12 py-4"><a class="text-2xl font-bold tracking-widest text-gray-900 dark:text-gray-100" href="/blog">블로그</a></div><div class="px-12 py-4"><a class="text-2xl font-bold tracking-widest text-gray-900 dark:text-gray-100" href="/tags">Tags</a></div></nav></div></div></div></header><main class="mb-auto"><div class="divide-y divide-gray-200 dark:divide-gray-700"><div class="space-y-2 pt-6 pb-8 md:space-y-5"><h1 class="text-3xl font-extrabold leading-9 tracking-tight text-gray-900 dark:text-gray-100 sm:text-4xl sm:leading-10 md:text-6xl md:leading-14">모든 게시물</h1><div class="relative max-w-lg"><input type="text" aria-label="Search articles" placeholder="검색" class="block w-full rounded-md border border-gray-300 bg-white px-4 py-2 text-gray-900 focus:border-primary-500 focus:ring-primary-500 dark:border-gray-900 dark:bg-gray-800 dark:text-gray-100"/><svg class="absolute right-3 top-3 h-5 w-5 text-gray-400 dark:text-gray-300" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M21 21l-6-6m2-5a7 7 0 11-14 0 7 7 0 0114 0z"></path></svg></div></div><ul><li class="py-4"><article class="space-y-2 xl:grid xl:grid-cols-4 xl:items-baseline xl:space-y-0"><dl><dt class="sr-only">Published on</dt><dd class="text-base font-medium leading-6 text-gray-500 dark:text-gray-400"><time dateTime="2024-05-04T00:00:00.000Z">2024년 5월 4일</time></dd></dl><div class="space-y-3 xl:col-span-3"><div><h3 class="text-2xl font-bold leading-8 tracking-tight"><a class="text-gray-900 dark:text-gray-100" href="/blog/20240505-falco">Falco를 활용하여 Terminal Shell 명령어 로그 수집하기</a></h3><div class="flex flex-wrap"><a class="mr-3 text-sm font-medium uppercase text-primary-500 hover:text-primary-600 dark:hover:text-primary-400" href="/tags/kubernetes">kubernetes</a><a class="mr-3 text-sm font-medium uppercase text-primary-500 hover:text-primary-600 dark:hover:text-primary-400" href="/tags/falco">falco</a><a class="mr-3 text-sm font-medium uppercase text-primary-500 hover:text-primary-600 dark:hover:text-primary-400" href="/tags/devsecops">devsecops</a></div></div><div class="prose max-w-none text-gray-500 dark:text-gray-400">Kubernetes Worker Node와 Pod Container에 Terminal shell로 접근하여 명령어를 입력하면 로그를 남기고, 경우에 따라서 알림을 보내고 싶었다. CNCF 졸업한 Project인 Falco를 활용하면 이를 구현할 수 있지 않을까 하여 테스트를 해보게 되었다. Falco는 kernel module이나 eBPF probe등을 통해서 kernel event를 저장하고, 설정된 rule에 따라서 해당 event를 filter하여 원하는 output 형태로 저장한다. Falco는 모든 로그를 저장하기보다는 Rule에 따라 선택적으로 보안 위협이 있는 이벤트를 수집하고 실시간으로 알림하는 것이 목적이다. 따라서 Falco를 통해서 원하던 기능을 구현하는 것은 합리적인 방법이 아닌 것으로 판단 된다.</div></div></article></li><li class="py-4"><article class="space-y-2 xl:grid xl:grid-cols-4 xl:items-baseline xl:space-y-0"><dl><dt class="sr-only">Published on</dt><dd class="text-base font-medium leading-6 text-gray-500 dark:text-gray-400"><time dateTime="2024-05-01T00:00:00.000Z">2024년 5월 1일</time></dd></dl><div class="space-y-3 xl:col-span-3"><div><h3 class="text-2xl font-bold leading-8 tracking-tight"><a class="text-gray-900 dark:text-gray-100" href="/blog/20240501-opentelemetry-syslog">OpenTelmetry로 auth.log와 syslog 수집하기</a></h3><div class="flex flex-wrap"><a class="mr-3 text-sm font-medium uppercase text-primary-500 hover:text-primary-600 dark:hover:text-primary-400" href="/tags/kubernetes">kubernetes</a><a class="mr-3 text-sm font-medium uppercase text-primary-500 hover:text-primary-600 dark:hover:text-primary-400" href="/tags/opentelemetry">opentelemetry</a><a class="mr-3 text-sm font-medium uppercase text-primary-500 hover:text-primary-600 dark:hover:text-primary-400" href="/tags/devsecops">devsecops</a></div></div><div class="prose max-w-none text-gray-500 dark:text-gray-400">Ubuntu 20.04 서버의 auth.log, syslog 로그 값들을 OpenTelemetry를 통해서 수집하고 싶었다. 처음에는 Filelog Receiver를 통해서 수집하려고 하였고, rsyslog의 설정값을 변경하여 Filelog로 수집하도록 구성했다. 그런데 이후에 Syslog Receiver가 존재하는 것을 확인하게 되었고, 훨씬 간단하게 syslog를 수집할 수 있었다.</div></div></article></li><li class="py-4"><article class="space-y-2 xl:grid xl:grid-cols-4 xl:items-baseline xl:space-y-0"><dl><dt class="sr-only">Published on</dt><dd class="text-base font-medium leading-6 text-gray-500 dark:text-gray-400"><time dateTime="2024-04-27T00:00:00.000Z">2024년 4월 27일</time></dd></dl><div class="space-y-3 xl:col-span-3"><div><h3 class="text-2xl font-bold leading-8 tracking-tight"><a class="text-gray-900 dark:text-gray-100" href="/blog/20240427-metastore-catalog-default">Spark에서 Hive database가 조회가 안 되는 문제</a></h3><div class="flex flex-wrap"><a class="mr-3 text-sm font-medium uppercase text-primary-500 hover:text-primary-600 dark:hover:text-primary-400" href="/tags/spark">spark</a></div></div><div class="prose max-w-none text-gray-500 dark:text-gray-400">Spark에서 SparkSession에 hive 설정을 해서 Hive의 데이터를 읽기/쓰기가 가능하다. 하지만 Hive에서 생성한 데이터베이스가 Spark에서는 조회가 되지 않았다. Spark에서 Hive Metastore를 Catalog로 사용할 때, hive-site.xml에 설정된 값을 이해하면 왜 조회가 되지 않는지 이해할 수 있다. hive-site.xml의 metadata.catalog.default 값이 어떻게 영향을 미치지는 살펴봤다.</div></div></article></li><li class="py-4"><article class="space-y-2 xl:grid xl:grid-cols-4 xl:items-baseline xl:space-y-0"><dl><dt class="sr-only">Published on</dt><dd class="text-base font-medium leading-6 text-gray-500 dark:text-gray-400"><time dateTime="2024-04-20T00:00:00.000Z">2024년 4월 20일</time></dd></dl><div class="space-y-3 xl:col-span-3"><div><h3 class="text-2xl font-bold leading-8 tracking-tight"><a class="text-gray-900 dark:text-gray-100" href="/blog/20240420-kubelet-imagegc">Kubelet imageGC</a></h3><div class="flex flex-wrap"><a class="mr-3 text-sm font-medium uppercase text-primary-500 hover:text-primary-600 dark:hover:text-primary-400" href="/tags/kubernetes">kubernetes</a><a class="mr-3 text-sm font-medium uppercase text-primary-500 hover:text-primary-600 dark:hover:text-primary-400" href="/tags/ncloud">ncloud</a></div></div><div class="prose max-w-none text-gray-500 dark:text-gray-400">사이즈가 큰 컨테이너 이미지를 내려받기 위해서 Containerd의 설정값 root을 새로운 스토리지를 추가한 경로로 수정하였다. Kubelet은 imageGCHighThresholdPercent로 설정된 임계치보다 disk 사용량이 많으면, 컨테이너 이미지를 정리하여 disk 공간을 확보하려고 한다. imageGCHighThresholdPercent이 기본값으로 85로 설정되어 있고, disk의 85 퍼센트 이상 사용했을 때 정리 프로세스가 실행된다. 문제는 Containerd root 경로의 volume이 거의 꽉 차더라도, 전체 volume의 사용량은 85 퍼센트가 되지 않을 수 있다는 것이다. Containerd root 경로의 volume에 여유가 없어서 새로 스케쥴된 Pod의 컨테이너 이미지를 내려 받지 못하는 문제가 발생할 수 있다. imageGCHighThresholdPercent 설정값을 조절하여 이 문제를 해결할 수 있다.</div></div></article></li><li class="py-4"><article class="space-y-2 xl:grid xl:grid-cols-4 xl:items-baseline xl:space-y-0"><dl><dt class="sr-only">Published on</dt><dd class="text-base font-medium leading-6 text-gray-500 dark:text-gray-400"><time dateTime="2024-04-20T00:00:00.000Z">2024년 4월 20일</time></dd></dl><div class="space-y-3 xl:col-span-3"><div><h3 class="text-2xl font-bold leading-8 tracking-tight"><a class="text-gray-900 dark:text-gray-100" href="/blog/20240420-loki-multi-tenants">Loki multi-tenants</a></h3><div class="flex flex-wrap"><a class="mr-3 text-sm font-medium uppercase text-primary-500 hover:text-primary-600 dark:hover:text-primary-400" href="/tags/kubernetes">kubernetes</a></div></div><div class="prose max-w-none text-gray-500 dark:text-gray-400">Loki로 Log를 수집하고, Grafana로 Log를 보여줄 때 Grafana user별로 볼 수 있는 Log를 제한하고 싶었다. Grafana Enterpirse의 경우에는 Label-based access control을 제공하여, Loki label별로 Query할 수 있는 권한을 제한할 수 있는 것처럼 보인다. 하지만 아쉽게 오픈소스에서는 해당 기능을 제공하지 않는다. 그래서 Loki multi tenant를 통해서 Log를 tenent별로 그룹핑하고, tenant별로 query하는 방법을 사용했다. 그리고 Loki는 인증 layer가 존재하지 않기 때문에 Nginx를 통해서 인증을 하여 query할 수 있도록 하였다. 마지막으로 Network Policy로 Nginx 인증을 통해서 Loki에 접근하도록 강제하여 원하는 구성을 할 수 있었다.</div></div></article></li><li class="py-4"><article class="space-y-2 xl:grid xl:grid-cols-4 xl:items-baseline xl:space-y-0"><dl><dt class="sr-only">Published on</dt><dd class="text-base font-medium leading-6 text-gray-500 dark:text-gray-400"><time dateTime="2024-03-24T00:00:00.000Z">2024년 3월 24일</time></dd></dl><div class="space-y-3 xl:col-span-3"><div><h3 class="text-2xl font-bold leading-8 tracking-tight"><a class="text-gray-900 dark:text-gray-100" href="/blog/20240324-book-review-what-can-a-body-do">책 &quot;다른 몸들을 위한 디자인&quot;을 읽고...</a></h3><div class="flex flex-wrap"><a class="mr-3 text-sm font-medium uppercase text-primary-500 hover:text-primary-600 dark:hover:text-primary-400" href="/tags/book">Book</a></div></div><div class="prose max-w-none text-gray-500 dark:text-gray-400">내가 일상 생활에서 장애를 직접 경험하지 않기 때문에 장애인이 경험하는 우리의 사회에 대해서 진지하게 고민할 기회가 많지 않았다. 봉사활동과 여러가지 프로젝트 참여를 통해서 장애인에 대한 여러가지 생각을 했지만, 내 삶에서 당장 중요한 문제가 아니다보니 일시적인 생각으로만 끝났다. 이 책을 읽으면서 느낀 점이나 생각들도 반복된 일상속에서 그냥 증발해버릴 것 같다는 생각이 들었다. 하지만 이러한 작은 관심과 생각들이 나의 무의식에 있던 사고들에 변화를 조금씩 가져오고, 그것이 쌓여서 나중에는 내가 무언가 사회에 조금이나마 영향을 미칠 수 있는 역할을 할 수 있지 않을까? 조금은 긍정적인 마음으로 독후감을 작성해보았다.</div></div></article></li><li class="py-4"><article class="space-y-2 xl:grid xl:grid-cols-4 xl:items-baseline xl:space-y-0"><dl><dt class="sr-only">Published on</dt><dd class="text-base font-medium leading-6 text-gray-500 dark:text-gray-400"><time dateTime="2024-03-24T00:00:00.000Z">2024년 3월 24일</time></dd></dl><div class="space-y-3 xl:col-span-3"><div><h3 class="text-2xl font-bold leading-8 tracking-tight"><a class="text-gray-900 dark:text-gray-100" href="/blog/20240324-k8s-device-plugin">k8s-device-plugin으로 NVIDIA GPU Multi-Process Service 사용하기</a></h3><div class="flex flex-wrap"><a class="mr-3 text-sm font-medium uppercase text-primary-500 hover:text-primary-600 dark:hover:text-primary-400" href="/tags/kubernetes">kubernetes</a><a class="mr-3 text-sm font-medium uppercase text-primary-500 hover:text-primary-600 dark:hover:text-primary-400" href="/tags/ncloud">ncloud</a></div></div><div class="prose max-w-none text-gray-500 dark:text-gray-400">Kubernetes에서 k8s-device-plugin을 통해서 NVIDIA GPU 자원을 쉽게 사용할 수 있다. 하나의 어플리케이션에서 GPU 자원을 온전히 사용하지 못하고 낭비될 때, Time slicing, MPS, MIG 등을 사용하여 여러 프로세스가 GPU 자원을 공유하도록 설정할 수 있다. 네이버 공공 클라우드에서 Tesla T4와 Telsa V100을 제공한다. 해당 GPU 아키텍쳐가 MIG을 지원히지 않기 때문에, MPS를 적용하여 GPU 자원을 공유하는 것을 고려하였다. 최근에 release된 k8s-device-plugin v0.15.0-rc.1부터 MPS가 지원되기 시작되어 해당 버전으로 MPS를 설정해보았다.</div></div></article></li><li class="py-4"><article class="space-y-2 xl:grid xl:grid-cols-4 xl:items-baseline xl:space-y-0"><dl><dt class="sr-only">Published on</dt><dd class="text-base font-medium leading-6 text-gray-500 dark:text-gray-400"><time dateTime="2024-02-14T00:00:00.000Z">2024년 2월 14일</time></dd></dl><div class="space-y-3 xl:col-span-3"><div><h3 class="text-2xl font-bold leading-8 tracking-tight"><a class="text-gray-900 dark:text-gray-100" href="/blog/20240214-containerd-LimitNOFILE">containerd nofile default 설정값</a></h3><div class="flex flex-wrap"><a class="mr-3 text-sm font-medium uppercase text-primary-500 hover:text-primary-600 dark:hover:text-primary-400" href="/tags/kubernetes">kubernetes</a><a class="mr-3 text-sm font-medium uppercase text-primary-500 hover:text-primary-600 dark:hover:text-primary-400" href="/tags/containerd">containerd</a></div></div><div class="prose max-w-none text-gray-500 dark:text-gray-400">Kubernetes에서 pod가 실행될 때, 해당 process의 open file 갯수 limit이 어떻게 되는지 궁금하였다. Containerd가 systemd service로 동작하는 상황에서 systemd에서 LimitNOFILE이 inifinity로 설정되어 있는 것을 확인하였다. infinity가 Ubuntu systemd 240 버전 이상에서는 process에 최대로 할당할 수 있는 File 갯수인 fs.nr_open 값으로 설정된다. 실제로 test용 pod를 띄어서 containerd에 의해서 실행되는 process의 nofile limit이 LimitNOFILE에 설정된 값으로 동일하게 설정되는 것을 확인하였다.</div></div></article></li><li class="py-4"><article class="space-y-2 xl:grid xl:grid-cols-4 xl:items-baseline xl:space-y-0"><dl><dt class="sr-only">Published on</dt><dd class="text-base font-medium leading-6 text-gray-500 dark:text-gray-400"><time dateTime="2024-02-11T00:00:00.000Z">2024년 2월 11일</time></dd></dl><div class="space-y-3 xl:col-span-3"><div><h3 class="text-2xl font-bold leading-8 tracking-tight"><a class="text-gray-900 dark:text-gray-100" href="/blog/20240208-tekton-chain">Tekton Chain</a></h3><div class="flex flex-wrap"><a class="mr-3 text-sm font-medium uppercase text-primary-500 hover:text-primary-600 dark:hover:text-primary-400" href="/tags/kubernetes">kubernetes</a><a class="mr-3 text-sm font-medium uppercase text-primary-500 hover:text-primary-600 dark:hover:text-primary-400" href="/tags/tekton">tekton</a><a class="mr-3 text-sm font-medium uppercase text-primary-500 hover:text-primary-600 dark:hover:text-primary-400" href="/tags/devsecops">devsecops</a></div></div><div class="prose max-w-none text-gray-500 dark:text-gray-400">Kubernetes에서 Tekton Chain을 통해서 어떻게 Software Supply Chain Security를 구성할 수 있는지 확인했다. Tekton Pipeline으로 git clone을 하고, container image를 build하고, 최종적으로 OCI registry에 push하도록 구성했다. 그리고 Tekton Chain이 어떻게 in-toto spec의 Attestation 정보를 남기는지 확인하였다.</div></div></article></li><li class="py-4"><article class="space-y-2 xl:grid xl:grid-cols-4 xl:items-baseline xl:space-y-0"><dl><dt class="sr-only">Published on</dt><dd class="text-base font-medium leading-6 text-gray-500 dark:text-gray-400"><time dateTime="2024-02-07T00:00:00.000Z">2024년 2월 7일</time></dd></dl><div class="space-y-3 xl:col-span-3"><div><h3 class="text-2xl font-bold leading-8 tracking-tight"><a class="text-gray-900 dark:text-gray-100" href="/blog/20240207-cilium-host-port">Cilium CNI와 HostPort</a></h3><div class="flex flex-wrap"><a class="mr-3 text-sm font-medium uppercase text-primary-500 hover:text-primary-600 dark:hover:text-primary-400" href="/tags/kubernetes">kubernetes</a><a class="mr-3 text-sm font-medium uppercase text-primary-500 hover:text-primary-600 dark:hover:text-primary-400" href="/tags/cilium">cilium</a></div></div><div class="prose max-w-none text-gray-500 dark:text-gray-400">네이버 클라우드 쿠버네티스 서비스에서 HostPort를 설정하였는데, 정상적으로 Node Port를 통해서 Container에 접근할 수가 없었다. 처음에는 CNI plugin portmap을 설정하여 HostPort를 Iptables Rule로 적용하도록 하였다. 하지만 현재 운영하는 Kernel 버전이 kube proxy를 대체할 수 있는 것을 파악하였고, default로 설정된 KubeProxyReplacement=disabled을 KubeProxyReplacement=strict으로 설정하여 Cilium eBPF로 대체하여 사용하였다.</div></div></article></li></ul></div><div class="space-y-2 pt-6 pb-8 md:space-y-5"><nav class="flex justify-between"><button rel="previous" class="cursor-auto disabled:opacity-50" disabled="">Previous</button><span>1<!-- --> of <!-- -->4</span><a href="/blog/page/2"><button rel="next">Next</button></a></nav></div></main><footer><div class="mt-16 flex flex-col items-center"><div class="mb-3 flex space-x-4"><a class="text-sm text-gray-500 transition hover:text-gray-600" target="_blank" rel="noopener noreferrer" href="mailto:jayground8@gmail.com"><span class="sr-only">mail</span><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" class="fill-current text-gray-700 hover:text-blue-500 dark:text-gray-200 dark:hover:text-blue-400 h-6 w-6"><path d="M2.003 5.884 10 9.882l7.997-3.998A2 2 0 0 0 16 4H4a2 2 0 0 0-1.997 1.884z"></path><path d="m18 8.118-8 4-8-4V14a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8.118z"></path></svg></a><a class="text-sm text-gray-500 transition hover:text-gray-600" target="_blank" rel="noopener noreferrer" href="https://github.com/jayground8"><span class="sr-only">github</span><svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg" class="fill-current text-gray-700 hover:text-blue-500 dark:text-gray-200 dark:hover:text-blue-400 h-6 w-6"><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"></path></svg></a></div><div class="mb-2 flex space-x-2 text-sm text-gray-500 dark:text-gray-400"><div>Jay</div><div> • </div><div>© 2024</div><div> • </div><a href="/">Jayground8</a></div><div class="mb-8 text-sm text-gray-500 dark:text-gray-400"><a target="_blank" rel="noopener noreferrer" href="https://github.com/timlrx/tailwind-nextjs-starter-blog">Tailwind Nextjs Theme</a></div></div></footer></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"initialDisplayPosts":[{"title":"Falco를 활용하여 Terminal Shell 명령어 로그 수집하기","date":"2024-05-04T00:00:00.000Z","tags":["kubernetes","falco","devsecops"],"images":["/static/images/social-banner.png"],"summary":"Kubernetes Worker Node와 Pod Container에 Terminal shell로 접근하여 명령어를 입력하면 로그를 남기고, 경우에 따라서 알림을 보내고 싶었다. CNCF 졸업한 Project인 Falco를 활용하면 이를 구현할 수 있지 않을까 하여 테스트를 해보게 되었다. Falco는 kernel module이나 eBPF probe등을 통해서 kernel event를 저장하고, 설정된 rule에 따라서 해당 event를 filter하여 원하는 output 형태로 저장한다. Falco는 모든 로그를 저장하기보다는 Rule에 따라 선택적으로 보안 위협이 있는 이벤트를 수집하고 실시간으로 알림하는 것이 목적이다. 따라서 Falco를 통해서 원하던 기능을 구현하는 것은 합리적인 방법이 아닌 것으로 판단 된다.","slug":"20240505-falco"},{"title":"OpenTelmetry로 auth.log와 syslog 수집하기","date":"2024-05-01T00:00:00.000Z","tags":["kubernetes","opentelemetry","devsecops"],"images":["/static/images/social-banner.png"],"summary":"Ubuntu 20.04 서버의 auth.log, syslog 로그 값들을 OpenTelemetry를 통해서 수집하고 싶었다. 처음에는 Filelog Receiver를 통해서 수집하려고 하였고, rsyslog의 설정값을 변경하여 Filelog로 수집하도록 구성했다. 그런데 이후에 Syslog Receiver가 존재하는 것을 확인하게 되었고, 훨씬 간단하게 syslog를 수집할 수 있었다.","slug":"20240501-opentelemetry-syslog"},{"title":"Spark에서 Hive database가 조회가 안 되는 문제","date":"2024-04-27T00:00:00.000Z","tags":["spark"],"images":["/static/images/social-banner.png"],"summary":"Spark에서 SparkSession에 hive 설정을 해서 Hive의 데이터를 읽기/쓰기가 가능하다. 하지만 Hive에서 생성한 데이터베이스가 Spark에서는 조회가 되지 않았다. Spark에서 Hive Metastore를 Catalog로 사용할 때, hive-site.xml에 설정된 값을 이해하면 왜 조회가 되지 않는지 이해할 수 있다. hive-site.xml의 metadata.catalog.default 값이 어떻게 영향을 미치지는 살펴봤다.","slug":"20240427-metastore-catalog-default"},{"title":"Kubelet imageGC","date":"2024-04-20T00:00:00.000Z","tags":["kubernetes","ncloud"],"images":["/static/images/social-banner.png"],"summary":"사이즈가 큰 컨테이너 이미지를 내려받기 위해서 Containerd의 설정값 root을 새로운 스토리지를 추가한 경로로 수정하였다. Kubelet은 imageGCHighThresholdPercent로 설정된 임계치보다 disk 사용량이 많으면, 컨테이너 이미지를 정리하여 disk 공간을 확보하려고 한다. imageGCHighThresholdPercent이 기본값으로 85로 설정되어 있고, disk의 85 퍼센트 이상 사용했을 때 정리 프로세스가 실행된다. 문제는 Containerd root 경로의 volume이 거의 꽉 차더라도, 전체 volume의 사용량은 85 퍼센트가 되지 않을 수 있다는 것이다. Containerd root 경로의 volume에 여유가 없어서 새로 스케쥴된 Pod의 컨테이너 이미지를 내려 받지 못하는 문제가 발생할 수 있다. imageGCHighThresholdPercent 설정값을 조절하여 이 문제를 해결할 수 있다.","slug":"20240420-kubelet-imagegc"},{"title":"Loki multi-tenants","date":"2024-04-20T00:00:00.000Z","tags":["kubernetes"],"images":["/static/images/social-banner.png"],"summary":"Loki로 Log를 수집하고, Grafana로 Log를 보여줄 때 Grafana user별로 볼 수 있는 Log를 제한하고 싶었다. Grafana Enterpirse의 경우에는 Label-based access control을 제공하여, Loki label별로 Query할 수 있는 권한을 제한할 수 있는 것처럼 보인다. 하지만 아쉽게 오픈소스에서는 해당 기능을 제공하지 않는다. 그래서 Loki multi tenant를 통해서 Log를 tenent별로 그룹핑하고, tenant별로 query하는 방법을 사용했다. 그리고 Loki는 인증 layer가 존재하지 않기 때문에 Nginx를 통해서 인증을 하여 query할 수 있도록 하였다. 마지막으로 Network Policy로 Nginx 인증을 통해서 Loki에 접근하도록 강제하여 원하는 구성을 할 수 있었다.","slug":"20240420-loki-multi-tenants"},{"title":"책 \"다른 몸들을 위한 디자인\"을 읽고...","date":"2024-03-24T00:00:00.000Z","tags":["Book"],"images":["/static/images/social-banner.png"],"summary":"내가 일상 생활에서 장애를 직접 경험하지 않기 때문에 장애인이 경험하는 우리의 사회에 대해서 진지하게 고민할 기회가 많지 않았다. 봉사활동과 여러가지 프로젝트 참여를 통해서 장애인에 대한 여러가지 생각을 했지만, 내 삶에서 당장 중요한 문제가 아니다보니 일시적인 생각으로만 끝났다. 이 책을 읽으면서 느낀 점이나 생각들도 반복된 일상속에서 그냥 증발해버릴 것 같다는 생각이 들었다. 하지만 이러한 작은 관심과 생각들이 나의 무의식에 있던 사고들에 변화를 조금씩 가져오고, 그것이 쌓여서 나중에는 내가 무언가 사회에 조금이나마 영향을 미칠 수 있는 역할을 할 수 있지 않을까? 조금은 긍정적인 마음으로 독후감을 작성해보았다.","slug":"20240324-book-review-what-can-a-body-do"},{"title":"k8s-device-plugin으로 NVIDIA GPU Multi-Process Service 사용하기","date":"2024-03-24T00:00:00.000Z","tags":["kubernetes","ncloud"],"images":["/static/images/social-banner.png"],"summary":"Kubernetes에서 k8s-device-plugin을 통해서 NVIDIA GPU 자원을 쉽게 사용할 수 있다. 하나의 어플리케이션에서 GPU 자원을 온전히 사용하지 못하고 낭비될 때, Time slicing, MPS, MIG 등을 사용하여 여러 프로세스가 GPU 자원을 공유하도록 설정할 수 있다. 네이버 공공 클라우드에서 Tesla T4와 Telsa V100을 제공한다. 해당 GPU 아키텍쳐가 MIG을 지원히지 않기 때문에, MPS를 적용하여 GPU 자원을 공유하는 것을 고려하였다. 최근에 release된 k8s-device-plugin v0.15.0-rc.1부터 MPS가 지원되기 시작되어 해당 버전으로 MPS를 설정해보았다.","slug":"20240324-k8s-device-plugin"},{"title":"containerd nofile default 설정값","date":"2024-02-14T00:00:00.000Z","tags":["kubernetes","containerd"],"images":["/static/images/social-banner.png"],"summary":"Kubernetes에서 pod가 실행될 때, 해당 process의 open file 갯수 limit이 어떻게 되는지 궁금하였다. Containerd가 systemd service로 동작하는 상황에서 systemd에서 LimitNOFILE이 inifinity로 설정되어 있는 것을 확인하였다. infinity가 Ubuntu systemd 240 버전 이상에서는 process에 최대로 할당할 수 있는 File 갯수인 fs.nr_open 값으로 설정된다. 실제로 test용 pod를 띄어서 containerd에 의해서 실행되는 process의 nofile limit이 LimitNOFILE에 설정된 값으로 동일하게 설정되는 것을 확인하였다.","slug":"20240214-containerd-LimitNOFILE"},{"title":"Tekton Chain","date":"2024-02-11T00:00:00.000Z","tags":["kubernetes","tekton","devsecops"],"images":["/static/images/social-banner.png"],"summary":"Kubernetes에서 Tekton Chain을 통해서 어떻게 Software Supply Chain Security를 구성할 수 있는지 확인했다. Tekton Pipeline으로 git clone을 하고, container image를 build하고, 최종적으로 OCI registry에 push하도록 구성했다. 그리고 Tekton Chain이 어떻게 in-toto spec의 Attestation 정보를 남기는지 확인하였다.","slug":"20240208-tekton-chain"},{"title":"Cilium CNI와 HostPort","date":"2024-02-07T00:00:00.000Z","tags":["kubernetes","cilium"],"images":["/static/images/social-banner.png"],"summary":"네이버 클라우드 쿠버네티스 서비스에서 HostPort를 설정하였는데, 정상적으로 Node Port를 통해서 Container에 접근할 수가 없었다. 처음에는 CNI plugin portmap을 설정하여 HostPort를 Iptables Rule로 적용하도록 하였다. 하지만 현재 운영하는 Kernel 버전이 kube proxy를 대체할 수 있는 것을 파악하였고, default로 설정된 KubeProxyReplacement=disabled을 KubeProxyReplacement=strict으로 설정하여 Cilium eBPF로 대체하여 사용하였다.","slug":"20240207-cilium-host-port"}],"posts":[{"title":"Falco를 활용하여 Terminal Shell 명령어 로그 수집하기","date":"2024-05-04T00:00:00.000Z","tags":["kubernetes","falco","devsecops"],"images":["/static/images/social-banner.png"],"summary":"Kubernetes Worker Node와 Pod Container에 Terminal shell로 접근하여 명령어를 입력하면 로그를 남기고, 경우에 따라서 알림을 보내고 싶었다. CNCF 졸업한 Project인 Falco를 활용하면 이를 구현할 수 있지 않을까 하여 테스트를 해보게 되었다. Falco는 kernel module이나 eBPF probe등을 통해서 kernel event를 저장하고, 설정된 rule에 따라서 해당 event를 filter하여 원하는 output 형태로 저장한다. Falco는 모든 로그를 저장하기보다는 Rule에 따라 선택적으로 보안 위협이 있는 이벤트를 수집하고 실시간으로 알림하는 것이 목적이다. 따라서 Falco를 통해서 원하던 기능을 구현하는 것은 합리적인 방법이 아닌 것으로 판단 된다.","slug":"20240505-falco"},{"title":"OpenTelmetry로 auth.log와 syslog 수집하기","date":"2024-05-01T00:00:00.000Z","tags":["kubernetes","opentelemetry","devsecops"],"images":["/static/images/social-banner.png"],"summary":"Ubuntu 20.04 서버의 auth.log, syslog 로그 값들을 OpenTelemetry를 통해서 수집하고 싶었다. 처음에는 Filelog Receiver를 통해서 수집하려고 하였고, rsyslog의 설정값을 변경하여 Filelog로 수집하도록 구성했다. 그런데 이후에 Syslog Receiver가 존재하는 것을 확인하게 되었고, 훨씬 간단하게 syslog를 수집할 수 있었다.","slug":"20240501-opentelemetry-syslog"},{"title":"Spark에서 Hive database가 조회가 안 되는 문제","date":"2024-04-27T00:00:00.000Z","tags":["spark"],"images":["/static/images/social-banner.png"],"summary":"Spark에서 SparkSession에 hive 설정을 해서 Hive의 데이터를 읽기/쓰기가 가능하다. 하지만 Hive에서 생성한 데이터베이스가 Spark에서는 조회가 되지 않았다. Spark에서 Hive Metastore를 Catalog로 사용할 때, hive-site.xml에 설정된 값을 이해하면 왜 조회가 되지 않는지 이해할 수 있다. hive-site.xml의 metadata.catalog.default 값이 어떻게 영향을 미치지는 살펴봤다.","slug":"20240427-metastore-catalog-default"},{"title":"Kubelet imageGC","date":"2024-04-20T00:00:00.000Z","tags":["kubernetes","ncloud"],"images":["/static/images/social-banner.png"],"summary":"사이즈가 큰 컨테이너 이미지를 내려받기 위해서 Containerd의 설정값 root을 새로운 스토리지를 추가한 경로로 수정하였다. Kubelet은 imageGCHighThresholdPercent로 설정된 임계치보다 disk 사용량이 많으면, 컨테이너 이미지를 정리하여 disk 공간을 확보하려고 한다. imageGCHighThresholdPercent이 기본값으로 85로 설정되어 있고, disk의 85 퍼센트 이상 사용했을 때 정리 프로세스가 실행된다. 문제는 Containerd root 경로의 volume이 거의 꽉 차더라도, 전체 volume의 사용량은 85 퍼센트가 되지 않을 수 있다는 것이다. Containerd root 경로의 volume에 여유가 없어서 새로 스케쥴된 Pod의 컨테이너 이미지를 내려 받지 못하는 문제가 발생할 수 있다. imageGCHighThresholdPercent 설정값을 조절하여 이 문제를 해결할 수 있다.","slug":"20240420-kubelet-imagegc"},{"title":"Loki multi-tenants","date":"2024-04-20T00:00:00.000Z","tags":["kubernetes"],"images":["/static/images/social-banner.png"],"summary":"Loki로 Log를 수집하고, Grafana로 Log를 보여줄 때 Grafana user별로 볼 수 있는 Log를 제한하고 싶었다. Grafana Enterpirse의 경우에는 Label-based access control을 제공하여, Loki label별로 Query할 수 있는 권한을 제한할 수 있는 것처럼 보인다. 하지만 아쉽게 오픈소스에서는 해당 기능을 제공하지 않는다. 그래서 Loki multi tenant를 통해서 Log를 tenent별로 그룹핑하고, tenant별로 query하는 방법을 사용했다. 그리고 Loki는 인증 layer가 존재하지 않기 때문에 Nginx를 통해서 인증을 하여 query할 수 있도록 하였다. 마지막으로 Network Policy로 Nginx 인증을 통해서 Loki에 접근하도록 강제하여 원하는 구성을 할 수 있었다.","slug":"20240420-loki-multi-tenants"},{"title":"책 \"다른 몸들을 위한 디자인\"을 읽고...","date":"2024-03-24T00:00:00.000Z","tags":["Book"],"images":["/static/images/social-banner.png"],"summary":"내가 일상 생활에서 장애를 직접 경험하지 않기 때문에 장애인이 경험하는 우리의 사회에 대해서 진지하게 고민할 기회가 많지 않았다. 봉사활동과 여러가지 프로젝트 참여를 통해서 장애인에 대한 여러가지 생각을 했지만, 내 삶에서 당장 중요한 문제가 아니다보니 일시적인 생각으로만 끝났다. 이 책을 읽으면서 느낀 점이나 생각들도 반복된 일상속에서 그냥 증발해버릴 것 같다는 생각이 들었다. 하지만 이러한 작은 관심과 생각들이 나의 무의식에 있던 사고들에 변화를 조금씩 가져오고, 그것이 쌓여서 나중에는 내가 무언가 사회에 조금이나마 영향을 미칠 수 있는 역할을 할 수 있지 않을까? 조금은 긍정적인 마음으로 독후감을 작성해보았다.","slug":"20240324-book-review-what-can-a-body-do"},{"title":"k8s-device-plugin으로 NVIDIA GPU Multi-Process Service 사용하기","date":"2024-03-24T00:00:00.000Z","tags":["kubernetes","ncloud"],"images":["/static/images/social-banner.png"],"summary":"Kubernetes에서 k8s-device-plugin을 통해서 NVIDIA GPU 자원을 쉽게 사용할 수 있다. 하나의 어플리케이션에서 GPU 자원을 온전히 사용하지 못하고 낭비될 때, Time slicing, MPS, MIG 등을 사용하여 여러 프로세스가 GPU 자원을 공유하도록 설정할 수 있다. 네이버 공공 클라우드에서 Tesla T4와 Telsa V100을 제공한다. 해당 GPU 아키텍쳐가 MIG을 지원히지 않기 때문에, MPS를 적용하여 GPU 자원을 공유하는 것을 고려하였다. 최근에 release된 k8s-device-plugin v0.15.0-rc.1부터 MPS가 지원되기 시작되어 해당 버전으로 MPS를 설정해보았다.","slug":"20240324-k8s-device-plugin"},{"title":"containerd nofile default 설정값","date":"2024-02-14T00:00:00.000Z","tags":["kubernetes","containerd"],"images":["/static/images/social-banner.png"],"summary":"Kubernetes에서 pod가 실행될 때, 해당 process의 open file 갯수 limit이 어떻게 되는지 궁금하였다. Containerd가 systemd service로 동작하는 상황에서 systemd에서 LimitNOFILE이 inifinity로 설정되어 있는 것을 확인하였다. infinity가 Ubuntu systemd 240 버전 이상에서는 process에 최대로 할당할 수 있는 File 갯수인 fs.nr_open 값으로 설정된다. 실제로 test용 pod를 띄어서 containerd에 의해서 실행되는 process의 nofile limit이 LimitNOFILE에 설정된 값으로 동일하게 설정되는 것을 확인하였다.","slug":"20240214-containerd-LimitNOFILE"},{"title":"Tekton Chain","date":"2024-02-11T00:00:00.000Z","tags":["kubernetes","tekton","devsecops"],"images":["/static/images/social-banner.png"],"summary":"Kubernetes에서 Tekton Chain을 통해서 어떻게 Software Supply Chain Security를 구성할 수 있는지 확인했다. Tekton Pipeline으로 git clone을 하고, container image를 build하고, 최종적으로 OCI registry에 push하도록 구성했다. 그리고 Tekton Chain이 어떻게 in-toto spec의 Attestation 정보를 남기는지 확인하였다.","slug":"20240208-tekton-chain"},{"title":"Cilium CNI와 HostPort","date":"2024-02-07T00:00:00.000Z","tags":["kubernetes","cilium"],"images":["/static/images/social-banner.png"],"summary":"네이버 클라우드 쿠버네티스 서비스에서 HostPort를 설정하였는데, 정상적으로 Node Port를 통해서 Container에 접근할 수가 없었다. 처음에는 CNI plugin portmap을 설정하여 HostPort를 Iptables Rule로 적용하도록 하였다. 하지만 현재 운영하는 Kernel 버전이 kube proxy를 대체할 수 있는 것을 파악하였고, default로 설정된 KubeProxyReplacement=disabled을 KubeProxyReplacement=strict으로 설정하여 Cilium eBPF로 대체하여 사용하였다.","slug":"20240207-cilium-host-port"},{"title":"Cert Manager Webhook 작성하여 Naver Cloud에서 DNS-01 challeng로 Lets Encrypt 인증서 발급하기","date":"2024-01-24T00:00:00.000Z","tags":["kubernetes","ncloud"],"images":["/static/images/social-banner.png"],"summary":"Cert Manager의 DNS provider 목록에 Naver Cloud DNS는 없었다. 하지만 Cert Manager에서 새로운 DNS provider를 직접 연결해서 사용할 수 있도록 webhook solver라는 것을 제공한다. 따라서 Naver Cloud API를 사용하여 webhook 코드를 작성하고, Github Action을 통해서 Image와 Helm chart를 배포해서 사용했다. Cert Manager에서 Boilerplate code와 test framework를 제공하여 비교적 쉽게 작성해서 사용할 수 있었다.","slug":"20240124-cert-manager-webhook"},{"title":"Adam Grant의 책 Hidden Potential을 읽고","date":"2024-01-21T00:00:00.000Z","tags":["Book"],"images":["/static/images/social-banner.png"],"summary":"내가 좋아하는 저자 Adam Grant의 새 책이 나와서 읽게 되었다. 성장 마인드셋을 믿지만, 성장이 정체되고 있다라는 불안감에 있는 나에게 큰 용기를 주는 책이었다. 다시 한번 나의 목표에 도달하기 위해서 내가 할 수 있는 시도들을 생각해보고, 조금씩이라도 어제보다 더 나아지는 오늘에 집중하자고 다짐했다. 지금까지 나의 성장들이 가파르게 우상향 한 것은 아니였다. 때로는 역석장 하는 것 같아서 불안하고 좌절했다. 하지만 전체 과정에서 컴포트 존을 나와 계속 도전을 해온 점과 성장하기 위해서 포기하지 않고 계속 노력해 온 점에 대해서 스스로 칭찬해주었다. 그리고 이 책을 통해서 아들의 성장과정에서 어떠한 것을 중요하게 생각하고 가르쳐줘야할지 고민해볼 수 있었다. 주도적으로 계속해서 배울 수 있는 힘을 배우고, 그 과정에서 재미도 느낄 수 있었으면 좋겠다","slug":"20240121-book-review-hidden-potential"},{"title":"GPTCache","date":"2024-01-06T00:00:00.000Z","tags":["GPTCache","ai"],"images":["/static/images/social-banner.png"],"summary":"GPTCache를 사용하여 LLM에 질의를 할 때, 의미적으로 유사한 질문에 대해서는 Cache에 저장된 답변 값을 사용할 수 있도록 구성해보았다. Langchain과 Langserve를 통해서 간단히 Cache를 제공하는 API server를 만들 수 있었다. Default로 설정된 GPTCache에서 의미적으로 충분히 다른 질의에 대해서도 기존 Cache값을 사용하는 False Positive 결과를 받았다. 그래서 Default로 사용된 Similarity Evaluation 방법이 어떻게 동작되는지 살펴보았다. 이해를 바탕으로 Threshold값을 변경하여 발생했던 False Positive case를 제거해보았다. 앞으로 Cache hit rate, Accuracy, Speed를 고려하여 서비스에 적합한 Evaluation 방법을 선택하기 위해서는 Default 말고 다른 옵션들도 확인할 필요가 있겠다.","slug":"20240106-gptcache"},{"title":"OpenTelemetry with Minikube","date":"2023-12-31T00:00:00.000Z","tags":["opentelemetry","kubernetes"],"images":["/static/images/social-banner.png"],"summary":"OpenTelemetry collector를 사용하여 tracing과 logging을 같이 하는 것을 검토하였다. Kubernetes와 멀어져 있던 사이에 OpenTelemetry 커뮤니티가 엄청나게 성장한 것을 깨닫게 되었다. Log에 traceID를 남기고 그걸로 Tracing 정보를 볼 수 있도록 구성했고, Grafana 하나에서 통합적으로 볼 수 있도록 Loki와 Tempo를 Exporter로 사용했다. 아직 Python과 Nodejs에서는 Log쪽의 상태는 Development나 Experimental이기 때문에, receiver에서 filelog를 사용하여 Kubernetes log file을 fluentbit처럼 tail해서 가져오고 traceId를 log에 넣어주는 instrument libary를 사용했다.","slug":"20231231-open-telemetry"},{"title":"Vault custom secret engine 작성해보기","date":"2023-12-28T00:00:00.000Z","tags":["vault","ncloud"],"images":["/static/images/social-banner.png"],"summary":"Vault의 secret engine을 사용하여 네이버 클라우드의 임시 인증키를 발행하고 싶었다. 네이버클라우드는 AWS, Azure처럼 builtin plugin으로 제공하지 않는다. 하지만 custom secret engine을 vault framework SDK를 통해서 쉽게 만들 수 있다. 네이버 클라우드에서 STS API를 제공하기 때문에, custom secret engine을 통해서 임시 인증키를 발행하는 것을 테스트 해보게 되었다. 처음에 구조를 이해하는데 좀 시간이 걸렸지만, Vault Tutorial에서 친절하게 설명하고 있어서 비교적 쉽게 만들 수 있었다.","slug":"20231228-vault-custom-secret-engine"},{"title":"vault secrets operator 사용해보기","date":"2023-12-22T00:00:00.000Z","tags":["Kubernetes","vault"],"images":["/static/images/social-banner.png"],"summary":"GitOps에서 Secret을 어떻게 관리할지 고민을 하였고, 개발자들의 인지부하를 줄이기 위해서 Vault UI로 자신의 앱의 비밀값을 관리하는 것이 제일 효율적이라는 판단을 했다. Vault secrets operator가 GA로 공유가 되었고, Secrets Store CSI나 External secrets 프로젝트보다 깔끔한 방식이라는 생각이 들었다. Vault secrets operator의 CRD로 vault secret과 kubernetes secret의 sync를 맞추고, reloader로 secret이 변경되었을 때 다시 pod를 배포하는 것을 테스트해보았다.","slug":"20231222-vault-on-k8s"},{"title":"AWS SAM으로 배포한 Lambda의 환경변수가 변경된 Secret Manager 값으로 반영이 안되는 문제","date":"2023-12-17T00:00:00.000Z","tags":["AWS"],"images":["/static/images/social-banner.png"],"summary":"AWS Cloudformation에서 Secret Manager의 값을 참조하도록 할 수 있다. AWS SAM을 사용하여 배포된 Lambda의 환경변수가 Secret Manager의 값을 참조하는 경우가 있었다. 그런데 Secret manager의 값을 변경하여 다시 배포하여도 변경된 값이 Lambda 환경변수에 반영이 되지 않았다.🧐 AWS SAM의 리포에 관련된 Issue가 있었고, 제안한 해결방법을 적용하였다. 살짝 삽질을 했기 때문에 기록을 남겨 본다.🤪","slug":"20231217-aws-sam-resolve-issue"},{"title":"Argo CD Notification으로 간단하게 Slack 알림 보내기","date":"2023-12-14T00:00:00.000Z","tags":["Kubernetes","ArgoCD"],"images":["/static/images/social-banner.png"],"summary":"Argo CD Notification가 이미 있어서 쉽게 Slack 알림을 연동할 수 있다. 메뉴얼에서 친절하게 셋팅 방법을 설명하고 있지만, 처음 보고 셋팅할 때 놓칠 수 있는 부분을 기록으로 남긴다.","slug":"20231214-argocd-notification"},{"title":"Kubernetes에서 Nginx로 IP allow list 제어","date":"2023-12-05T00:00:00.000Z","tags":["Kubernetes","Nginx"],"images":["/static/images/social-banner.png"],"summary":"Kubernetes cluster에서 Nginx로 허용 가능한 IP를 설정하고 싶었다. 간단하게 끝날 줄 알았던 작업은 또다른 삽질기가 되었다.😭 Kubernetes에서 SNAT이 되는 과정을 이해하고 externalTrafficPolicy를 Local로 설정했다. 그리고 External Load balancer에서는 client IP를 전달하기 위해서 Proxy Protocol와 같은 것을 설정하고, Nginx에서 그 Proxy protocol로 전달된 IP address로 Access control을 할 수 있도록 설정하였다.","slug":"20231205-nginx-allow-ip"},{"title":"CNAME flattening","date":"2023-11-22T00:00:00.000Z","tags":["DNS"],"images":["/static/images/social-banner.png"],"summary":"CNAME flattening이 어떻게 작동하고, 왜 사용하게 되었는지 이해하게 되었다.","slug":"20231122-cname-flattening"},{"title":"책 \"유난한 도전\"과 \"무브업\"을 읽고나서...","date":"2023-11-19T00:00:00.000Z","tags":["book"],"images":["/static/images/social-banner.png"],"summary":"책 \"유난한 도전\"를 시간 가는 줄 모르고 재미있게 읽었다. 토스의 초기부터 최근까지 겪었던 우여곡절과 그 속에서 만들어낸 성공 스토리들을 읽으면서, 내 가슴에 뭔가 꿈틀꿈틀 거리는 열정과 흥분을 느꼈다. 또 다시 주도적인 변화를 만들어내고 싶다는 열정을 가지게 된 것과 동시에 나는 그러한 치열함과 멋진 커리어를 가지지 못했다는 불안감을 가지게 되었다. 책 \"무브업\"은 나의 커리어적인 불암감에 위에 양념을 살짝 더 뿌려줬다. 하지만 그래도 이제는 그러한 불안감에 압도당하지 않고, 내가 주어진 하루에서 내가 할 수 있는 최선을 고민하는 할 수 있다.","slug":"20231119-book-review"},{"title":"CVE 취약점 확인하고 Ubuntu Kernel Update 해보기","date":"2023-11-11T00:00:00.000Z","tags":["ubuntu","security"],"images":["/static/images/social-banner.png"],"summary":"OpenSCAP으로 Ubuntu20.04 이미지를 사용하는 가상서버의 취약점 리포트를 만들어보고, 보고된 취약점이 패치된 커널 버전으로 업그레이드 하여 해당 이슈를 해결해보았다. 이렇게 업그레이드 된 커널과 패키지들이 정상적으로 작동하는지 확인하고 사용할 수 있는 파이프라인을 만드는 것도 나중에 고민해봐야겠다.","slug":"20231111-update-ubuntu-kernel"},{"title":"Kubernetes에서 GPU 사용하기","date":"2023-10-29T00:00:00.000Z","tags":["kubernetes"],"images":["/static/images/social-banner.png"],"summary":"Pytorch를 컨테이너로 띄우고 GPU를 사용하고 싶었다. 따라서 Docker container에서 NVIDIA GPU를 사용할 수 있도록 셋팅을 해보았다. 그리고 최종적으로 Kubernetes에서 GPU hardware를 사용할 수 있도록 nvidia device plugin을 DaemonSet으로 띄우고 Pod를 실행해보았다.","slug":"20231029-gpu-on-k8s"},{"title":"aws-ebs-csi-driver 코드로 csi driver 이해하기","date":"2023-10-21T00:00:00.000Z","tags":["kubernetes"],"images":["/static/images/social-banner.png"],"summary":"aws-ebs-csi-driver 소스코드를 보고 csi driver가 하는 역할을 이해해보았다. 크게 Controller plugin과 Node plugin으로 구성되어 있고, 다양한 sidecar container들이 존재한다. 이 sidecar container들이 Volume을 생성하고, 노드에 부착하고, Host 혹은 container directory에 mount하는 것을 진행한다. 이과정에서 CSI driver로 cloud vendor마다 다른 로직으로 그들의 volume을 제어하게 된다. 네이버 클라우드에서 storage가 처음 생성될 때 서버에 부착이 되어야만 하는 제약사항이 있어서, PVC로 PV 동적 할당을 할 때 volumeBindingMode이 Immediate이면 자동으로 Node에 부착이 된다.","slug":"20231021-csi-driver"},{"title":"네이버 클라우드 certificate manager에 Lets encrypt 인증서 등록하기","date":"2023-10-14T00:00:00.000Z","tags":["ncloud"],"images":["/static/images/social-banner.png"],"summary":"Lets encrypt로 인증서를 발급하여 이것을 Naver Cloud Certificate Manager에 등록하려고 하였다. certbot을 통해서 인증서를 발급받고 해당 파일들을 Certificate manager에 등록하려고 하니 에러가 발생하였다. 이번 블로그 포스팅은 두 가지의 에러를 해결한 삽질기이다.","slug":"20231014-ncloud-certificate-manater"},{"title":"ECR Credential-Provider 사용해보기","date":"2023-09-28T00:00:00.000Z","tags":["kubernetes"],"summary":"Kubeadm으로 만든 Kubernetes Cluster에서 AWS ECR를 private container image repository를 사용하고자 하였다. private repository를 접근하기 위해서 Kubernetes 1.26부터 stable feature로 제공하는 kubelet crendential provider를 사용하였다.","slug":"20230928-ecr-credential-provider"},{"title":"S3에서 Internet으로 데이터 송신한 금액을 bucket별로 확인하기","date":"2023-09-28T00:00:00.000Z","tags":["aws"],"images":["/static/images/social-banner.png"],"summary":"인터넷에서 S3의 file을 다운로드하면 데이터 전송 비용이 발생한다. 서울 리전 기준으로는 처음 월 10TB까지는 GB당 0.126USD 요금이 발생한다. 이렇게 발생한 금액을 S3 bucket별로 나눠서 볼려면 어떻게 해야 할까? AWS Cost and Usage Report 서비스를 사용하면 세부적인 사용내역을 얻을 수 있고, 그 데이터를 분석하면 bucket별로 인터넷 데이터 전송에 의해 발생한 금액을 산출할 수 있다.","slug":"20230928-s3-data-transfer-out"},{"title":"콜드 스타트 이론","date":"2023-08-04T00:00:00.000Z","tags":["book"],"summary":"\u003c콜드 스타트\u003e 책은 네트워크 상품이 어떻게 성장하고, 성장과 함께 어떠한 단계를 경험할 수 있는지 설명한다. 새로운 네트워크 상품은 네트워크를 처음부터 구축해야 되는 콜드 스타트 문제를 가진다. 작지만 밀도가 높은 원자적 네트워크를 구성하여 초기 콜드 스타트 문제를 해결해야 하고, 이것은 초기 생존과 연관된다. 원자적 네트워크를 바탕으로 확장하고 네트워크가 성장하면 네트워크 효과를 가질 수 있다. 동일한 기능을 모방하여 도전하는 경쟁자가 생긴다고 해도 네트워크 효과가 방어막이 될 수 있다.","slug":"20230804-book-review-the-cold-start-problem"},{"title":"내가 해결한 문제 중 가장 어려운 문제는 무엇이었나?","date":"2023-07-31T00:00:00.000Z","tags":["self-evalutaion"],"summary":"오늘 나를 돌이켜보면서 난해만 문제들을 정의하고 그것들을 해결해나가는 실질적인 경험이 너무 부족하다는 것을 느꼈다. \"나는 진짜 어려운 문제를 해결한 적이 없었는데... 이걸 어려운 문제라고 할 수 있을까...?\" 이러한 고민에 주저하지 않고 당당히 말할 수 있는 경험들을 앞으로라도 만들어 나가야겠다.","slug":"20230731-what-have-you-solved"},{"title":"오픈소스 Kubernetes External Secrets 살펴보기","date":"2023-07-30T00:00:00.000Z","tags":["kubernetes"],"summary":"CRD와 Custom Controller를 사용하는 프로젝트에 대해서 더 알고 싶은 상황에서, External Secrets이라는 프로젝트를 발견하게 되었다. External Secrets는 Vault, AWS secret manager와 같이 secret 관리하는 Tool들과 Kubernetes secret을 CRD을 통해서 sync할 수 있게 해준다. 이 프로젝트는 kubebuilder를 사용하였는데, 소스코드를 보면서 어떻게 구현한 건지 자세히 살펴보았다.","slug":"20230730-k8s-controller-external-secrets"},{"title":"행동 설계 7단계를 내 실생활에 적용해보자","date":"2023-07-23T00:00:00.000Z","tags":["book"],"summary":"책 \"훅(Hooked)\"에서 포그 행동모델을 알게 되었다. 이번에는 포그가 쓴 책 \"습관의 디테일(Tiny Habits)\"을 읽어 보게 되었다. 내가 과거에 습관으로 잘 형성했던 행동들을 행동 모델 7단계 관점에서 생각을 해보았다. 그리고 내가 습관화 하지 못했던 행동들에 대해서도 생각해보면서 다시 한번 어떻게 꾸준히 할 수 있을까 고민해보았다. 알고리즘 꾸준히 공부하기는 내가 습관화 하고 싶었던 것 중에 하나였는데 매번 실패하는 행동이었다. 이번에 행동 모델 7단계에 내용들을 적용하여 다시 시도해본다.","slug":"20230723-book-review-tiny-habit"},{"title":"Calico kube-controller 이해하기","date":"2023-07-22T00:00:00.000Z","tags":["kubernetes","calico"],"summary":"Calico에서 어떻게 CRD를 활용하는지 이해하기 위해서 Calico Opensource 버전의 깃헙 소스코드를 살펴보게 되었다. Calico archiecture에서 kube-controller 부분이 어떤 역할을 하는지 소스 코드를 통해서 이해할 수 있게 되었다. kube-controller들은 kubernetes native resource에 대한 변경을 calico data store와 sync해주는 역할을 하고 있다. 내가 사용하는 Minikbue Kubernetes Cluster에서는 Calico의 data store는 kubernetes로 설정되어 있기 때문에, CRD로 Calico data들이 저장되고 Felix가 이것을 watch하여 변화에 대해서 network rule을 업데이트 하게 된다.","slug":"20230722-calico-kube-controller"},{"title":"책 두 권 \u003c초집중\u003e, \u003c훅\u003e","date":"2023-07-17T00:00:00.000Z","tags":["book"],"summary":"나의 집중력을 되찾고 싶은 마음에 책 \u003c초집중\u003e을 읽었다. 그리고 애 책의 저자중 한명이 과거에 쓴 \u003c훅\u003e도 읽게 되었다. \u003c흑\u003e은 2014년에 출간된 책으로 조금 오래된 책이지만, 사업모델이 습관에 의존한다면 이 책이 도움이 될거라는 설명에 읽어보게 되었다. 계기, 행동, 가변적 보상, 투자라는 키워드를 현재 내가 일하고 있는 프로덕트와 내가 한번 쯤 만들어보고 싶은 서비스와 연관지어서 생각해보는 시간을 가졌다. 그 과정에서 떠오른 아이디어도 PM분들과 공유해보았다.","slug":"20230717-book-review-indistractable-hooked"},{"title":"if(kakao)2022 Testing Kubernetes Controller 발표 따라 만들기","date":"2023-07-16T00:00:00.000Z","tags":["kubernetes"],"summary":"어제는 Programming Kubernetes에 나오는 예제를 kubebuilder로 작성해보았다. if(kakao)2022에서 controller를 테스트하는 방법에 대해서 설명한 발표가 있었다. 어제 이해한 내용을 바탕으로 이 발표에서 사용한 BlueGreen controller 예제를 따라서 작성해보았다.","slug":"20230716-if-kakao-2022-k8s-controller"},{"title":"Kubernetes custom controller 작성해보기","date":"2023-07-15T00:00:00.000Z","tags":["kubernetes"],"summary":"Programming Kubernetes 책에서 나온 예제를 따라서 custom controller를 작성해보았다. CustomResourceDefinition를 어떻게 정의하고, kubebuilder로 어떻게 나만의 business logic을 작성할 수 있는지 예제를 통해서 이해했다.","slug":"20230715-k8s-controller"},{"title":"흑역사 하나 더 만들기","date":"2023-07-03T00:00:00.000Z","tags":["kubernetes","presentation"],"summary":"오늘 대왕 흑역사를 생산했다. Kubernetes Community Days에서 발표를 하게 되었는데, 30분 발표시간에 맞춰서 발표자료를 잘 준비하지 못해서 부끄러웠다. 30분에 너무 많은 내용을 담을려고 했고, 라이브코딩 형식으로 해서 시간도 많이 걸렸다. 나는 발표를 왜 할까?","slug":"20230703-k8s-community-days"},{"title":"노코드 개발 체험해보기","date":"2023-06-25T00:00:00.000Z","tags":["nocode"],"summary":"노코드 개발 생태계가 궁금했는데, 마침 노코드 API 서버를 개발하는 공모전이 있어서 참가했다. SyncTree로 API를 개발하고, Airtable을 데이터베이스로 사용하였다. Front는 Weweb이나 Bubble로 작성하려고 했으나, 유료 plan에서만 deploy가 가능하여 vercel에서 간단하게 react SPA를 배포했다.","slug":"20230625-no-code-tools"},{"title":"책 읽으면서 생각한 나의 개발자 커리어 개발","date":"2023-06-24T00:00:00.000Z","tags":["book"],"summary":"나는 어떻게 대체 되지 않는 개발자가 될 수 있을까? 다양한 책들을 읽으면서 나의 개발자 커리어를 회고해보고 어떻게 앞으로 살아가야할까 고민을 해보았다. 엔지니어링 기술과 인간의 상호작용을 통해서 어려운 문제들을 해결해나갈 수 있는 개발자가 되어야 한다. 어떻게 그렇게 될 수 있을까?","slug":"20230624-book-review-replacable"},{"title":"장기기억, 경제적 자유, 스토리","date":"2023-06-16T00:00:00.000Z","tags":["book"],"summary":"최근에 읽은 책들을 바탕으로 장기기억, 경제적 자유, 스토리에 대해서 생각해보았다. \"기억의 뇌과학\", \"세컨드 브레인\" 책등을 통해서 다시 한번 나의 학습을 어떻게 장기기억화 할 것인가 고민해보았다. \"역행자\", \"부의 근원\", \"돈은 너로부터이다\" 책등을 통해서는 내가 어떻게 경제적 자유를 이룰 수 있을지 고민했다. 마지막으로 \"스토리만이 살길\", \"프리워커스\" 책등을 통해서는 스토리의 힘을 깨달았다.","slug":"20230616-book-review"},{"title":"내가 만들어 보고 싶은 서비스","date":"2023-06-10T00:00:00.000Z","tags":["idea"],"summary":"회사는 성장하고, 그 성장을 바탕으로 충분한 매출과 이익이 발행하고, 회사의 가치가 높아져서 투자자에게도 금전적인 보상을 제공할 수 있는 흐름을 가지고 있다. 나는 다른 방식으로 접근하는 회사를 만들어 보고 싶다. 이미 사회적 기업이나 협동조합 같은 형식으로 존재하고, 이는 위에서 설명한 회사와는 다른 흐름을 가진다. 이와 비슷하게 스타트업이 투자를 받아서 폭발적으로 성장해야 되는 것이 아니라, 사용자가 소수라도 충분히 가치를 제공하고 유지할 수 있는 서비스를 제공하는 회사를 만들고 싶다.","slug":"20230610-new-service"}],"pagination":{"currentPage":1,"totalPages":4}},"__N_SSG":true},"page":"/blog","query":{},"buildId":"PWwclqFnWkHCY0t6gTyza","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>